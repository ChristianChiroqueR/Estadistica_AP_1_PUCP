[["index.html", "Estadística para el Análisis Político I Sesión 1 Introducción a Estadística con R 1.1 Estadística: los fundamentos 1.2 R: los fundamentos 1.3 Importación y exploración de datos", " Estadística para el Análisis Político I Docente: Christian Chiroque Ruiz 2023-10-08 Sesión 1 Introducción a Estadística con R 1.1 Estadística: los fundamentos La estadística es una rama de las matemáticas que se enfoca en el análisis, interpretación y presentación de datos. Los estadísticos se centran en la teoría estadística y en el desarrollo de métodos para analizar datos. Los estadísticos también pueden diseñar estudios experimentales para recopilar datos de una manera rigurosa y controlada. En términos generales, la estadística se divide en dos áreas principales: estadística descriptiva y estadística inferencial. La estadística descriptiva se centra en la organización y presentación de datos, mientras que la estadística inferencial se ocupa de la inferencia y la predicción a partir de datos. 1.1.1 Unidad de análisis En estadística, una unidad de análisis se refiere a la entidad o elemento individual que se estudia en una investigación o estudio estadístico. Esta entidad puede ser una persona, un animal, un objeto, una organización, un evento, una muestra, etc. Dependiendo del objetivo del estudio y de la pregunta que se pretenda responder, la unidad de análisis puede variar. Es importante tener en cuenta que la elección de la unidad de análisis puede tener un impacto significativo en los resultados de un estudio estadístico. Por lo tanto, es fundamental definir claramente la unidad de análisis y asegurarse de que sea coherente con los objetivos y la hipótesis de la investigación. 1.1.2 Tipos de variables y escalas de medición Tipos de variable En estadística, una variable es cualquier característica, propiedad o atributo que puede tomar diferentes valores y que se puede medir o observar en los elementos de una población o muestra. Distinguimos los tipos de variables porque diferentes métodos estadísticos pueden ser aplicados a cada tipo. Tipos Variables numéricas Variables categóricas Características - Se expresan en términos numéricos y se pueden medir con precisión.- Los valores representan diferentes magnitudes (cantidad) de la variable. - No se expresan en términos numéricos y no se pueden medir con precisión.- Se miden utilizando un conjunto de categorías o etiquetas. Ejemplos - Ingreso anual- Número de sobrinos- Edad- Número de años de estudio. - Estado civil- Departamento de residencia- Tipo de música favorita. Alias También denominadas cuantitativas. También denominadas cualitativas. Escalas de medición Identifica cómo es medida la variable. Para las variables numéricas: Se utiliza la escala de intervalo: Existe una distancia específica entre cada par de valores y es comparable. Ej: Existe la misma distancia entre 1500 y 1000 soles que entre 1000 soles y 500 soles. Para las variables categóricas: Se utiliza: Escala nominal: Si las categorías no están ordenadas (no hay un alto o bajo, o comparación de intensidad). Las distintas categorías son llamadas “niveles”. Escala ordinal: Es un caso particular. No son nominales porque tienen un orden natural y no son numéricas porque usan etiquetas (niveles). Ej: Nivel de satisfacción con el Poder Ejecutivo. 1.2 R: los fundamentos 1.2.1 ¿Por qué R? R es un lenguaje de programación y un entorno de software libre orientado principalmente al análisis estadístico y la representación gráfica de datos. Desde su creación en 1993 por Ross Ihaka y Robert Gentleman en la Universidad de Auckland, R ha evolucionado para convertirse en una de las herramientas más populares y poderosas en el campo de la estadística y la ciencia de datos. Aprender estadística con R tiene varias ventajas: Ventaja Detalle Flexibilidad y Personalización R ofrece un amplio rango de análisis y permite la personalización y automatización según las necesidades del usuario. Amplio Repositorio de Paquetes La comunidad de R ha desarrollado miles de paquetes, permitiendo fácil acceso a técnicas estadísticas avanzadas. Reproducibilidad Con R, se pueden crear análisis que otros investigadores pueden verificar y replicar fácilmente. Representación Gráfica R destaca en la producción de gráficos de alta calidad, esenciales para la visualización de datos. Comunidad Activa La activa comunidad de R proporciona numerosos recursos, tutoriales y foros para el aprendizaje y resolución de dudas. 1.2.2 POO R es un lenguaje de programación que adopta el paradigma de la “programación orientada a objetos”. Esto significa que, en R, todo se considera un “objeto”, ya sea un conjunto de datos, una función o un modelo. Cada objeto tiene atributos y comportamientos asociados que determinan cómo se puede interactuar con él. Esta estructura permite a los usuarios de R organizar y manipular datos de manera coherente y sistemática. Al entender que todo en R es un objeto, se puede abordar el análisis estadístico con una visión más estructurada, lo que facilita la comprensión y aplicación de técnicas y métodos avanzados en el futuro. Imagina que cada objeto en R es como un coche. Los “atributos” de ese coche pueden incluir su color, marca, modelo, y año de fabricación. Estos atributos describen las características específicas del coche. Ahora, piensa en los “comportamientos asociados” como las acciones que puedes realizar con ese coche: encenderlo, acelerar, frenar o encender las luces. Del mismo modo, en R, un objeto, como un conjunto de datos, podría tener atributos que describan su tamaño, tipo y estructura. Y los comportamientos asociados de ese conjunto de datos podrían incluir operaciones como filtrar, ordenar o aplicar una función estadística. Por ejemplo, si tienes un objeto en R que es un dataframe (un tipo de estructura de datos tabular), sus “atributos” podrían incluir el número de filas y columnas, los nombres de las columnas y el tipo de datos en cada columna. Los “comportamientos asociados” de ese dataframe podrían ser operaciones como añadir o eliminar una columna, filtrar por ciertos valores o calcular estadísticas sobre una columna específica. Al comprender los atributos y comportamientos de los objetos en R, puedes manipularlos y analizarlos de manera efectiva y eficiente, al igual que un conductor experto sabe cómo manejar y cuidar su coche. 1.2.3 Los objetos Vamos a examinar la clase de algunos de los elementos más básicos en R: los números, los caracteres y los elementos lógicos. class(1.5) ## [1] &quot;numeric&quot; # Para escribir valores character siempre entre comillas class(&quot;rojo&quot;) ## [1] &quot;character&quot; # Para escribir valores booleanos siempre usar mayúscula. class(TRUE) ## [1] &quot;logical&quot; En R, los datos pueden ser coercionados, es decir, forzados, para transformarlos de un tipo a otro. as.numeric(&quot;5&quot;) ## [1] 5 as.integer(5.1) ## [1] 5 as.character(5) ## [1] &quot;5&quot; Podemos asignarles etiquetas (nombres) a esos elementos. x &lt;- 5.5 class(x) ## [1] &quot;numeric&quot; y &lt;- &quot;perro&quot; class(y) ## [1] &quot;character&quot; z &lt;- TRUE class(z) ## [1] &quot;logical&quot; Considerar que también se puede usar el signo “=”. Sin embargo, tiene algunas diferencias en cuanto a su uso en el programa. Por ejemplo, uno puede escribir esta sentencia X &lt;-5+5 y 5+5-&gt;X. Sin embargo, el sistema no acepta lo siguiente: 5+5 = X 1.2.4 Los vectores Un vector es una colección de uno o más datos del mismo tipo. Tipo. Un vector tiene el mismo tipo que los datos que contiene. Si tenemos un vector que contiene datos de tipo numérico, el vector será también de tipo numérico. Los vectores son atómicos, pues sólo pueden contener datos de un sólo tipo, no es posible mezclar datos de tipos diferentes dentro de ellos. Largo. Es el número de elementos que contiene un vector. El largo es la única dimensión que tiene esta estructura de datos. NO TIENE DIMENSIÓN (dim) Ejemplo: Vamos a crear tres vectores: uno numérico, uno de caracter y uno lógico. Podemos utilizar la función length() para medir el largo de estos (cuántos elementos contiene). vector_numerico &lt;- c(1, 2, 3, 4, 5) length(vector_numerico) ## [1] 5 vector_caracter &lt;- c(&quot;arbol&quot;, &quot;casa&quot;, &quot;persona&quot;) length(vector_caracter) ## [1] 3 vector_logico&lt;- c(TRUE, TRUE, FALSE, FALSE, TRUE) length(vector_logico) ## [1] 5 También podemos utilizar la función class() para corroborar que cada vector tiene la misma clase de los elementos que contiene. class(vector_numerico) ## [1] &quot;numeric&quot; class(vector_caracter) ## [1] &quot;character&quot; class(vector_logico) ## [1] &quot;logical&quot; Tener en cuenta que los vectores también pueden tener valores perdidos (NA). vector_con_NA &lt;- c(1,2,3,NA,5) length(vector_con_NA) ## [1] 5 class(vector_con_NA) ## [1] &quot;numeric&quot; 1.2.5 Los factores Un factor es un tipo específico de vector en R. Puede ser descrito como un dato numérico representado por una etiqueta. Supongamos que tenemos un conjunto de datos que representan el género de personas encuestadas por teléfono, pero estos se encuentran capturados con los números 1 y 2. genero &lt;- c(1,1,1,2,2,1,2) El número 1 corresponde a Mujer y el 2 a Hombre. A diferencia del carácter, el factor tiene NIVELES (levels). Podemos crear un vector de tipo factor con la función factor(). genero_en_factor=factor(genero, levels= 1:2, labels=c(&quot;Mujer&quot;, &quot;Hombre&quot;)) genero_en_factor ## [1] Mujer Mujer Mujer Hombre Hombre Mujer Hombre ## Levels: Mujer Hombre En la práctica, muchas veces vamos a ver las variables de tipo factor en nuestro análisis. Por ello, debes ser muy cuidadoso en la preparación previa que debes realizar a la base de datos antes de aplicar las funciones. Asimismo, un factor puede estar ordenado o no ordenado. Esto nos sirve, por ejemplo, para crear variables de tipo ordinal. Podemos indicarlo ello, con el argumento ordered=. Veamos: confianza=c(1, 1, 3, 2) confianza_en_factor=factor(confianza, levels= 1:3, labels=c(&quot;Bajo&quot;, &quot;Medio&quot;, &quot;Alto&quot;), ordered = TRUE) confianza_en_factor ## [1] Bajo Bajo Alto Medio ## Levels: Bajo &lt; Medio &lt; Alto Vemos que nos indica los niveles, pero en este caso están ordenados de menor a mayor. 1.2.6 Data frames Los data frames son estructuras de datos de dos dimensiones (rectangulares) que pueden contener datos de diferentes tipos, por lo tanto, son heterogéneas. Compuesto por vectores. Estructura más usada para ciencia de datos. Mientras que en una matriz todas las celdas deben contener datos del mismo tipo, los renglones de un data frame admiten datos de distintos tipos, pero sus columnas conservan la restricción de contener datos de un sólo tipo. En términos generales, los renglones en un data frame representan casos, individuos u observaciones, mientras que las columnas representan atributos, rasgos o variables. mi_df &lt;- data.frame( &quot;variable1&quot; = 1:3, &quot;variable2&quot; = c(1.2, 3.4, 4.5), &quot;variable3&quot; = as.character(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;)), &quot;variable4&quot; = as.factor(c(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;)) ) #Para crear un DT los vectores de insumo deben ser del mismo largo mi_df ## variable1 variable2 variable3 variable4 ## 1 1 1.2 a 1 ## 2 2 3.4 b 2 ## 3 3 4.5 c 3 str(mi_df) ## &#39;data.frame&#39;: 3 obs. of 4 variables: ## $ variable1: int 1 2 3 ## $ variable2: num 1.2 3.4 4.5 ## $ variable3: chr &quot;a&quot; &quot;b&quot; &quot;c&quot; ## $ variable4: Factor w/ 3 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;: 1 2 3 Propiedades Un data.frame tiene: Dimensión: un número de filas y un número de columnas. dim(mi_df) #FILAS Y COLUMNAS ## [1] 3 4 Largo: número de casos length(mi_df) ## [1] 4 Nombre de columnas: Podemos consultar el nombre de las columnas (variables) con la función names(). names(mi_df) ## [1] &quot;variable1&quot; &quot;variable2&quot; &quot;variable3&quot; &quot;variable4&quot; 1.2.7 Índices Usar índices para obtener subconjuntos es el procedimiento más universal en R, pues funciona para todas las estructuras de datos. Un índice en R representa una posición. Cuando usamos índices le pedimos a R que extraiga de una estructura los datos que se encuentran en una o varias posiciones específicas dentro de ella. Ejemplos: Seleccionar la columna 2: mi_df [,2] ## [1] 1.2 3.4 4.5 Para seleccionar una columna, también podemos usar el símbolo de $. Es bastante usado en varias funciones. mi_df$variable2 ## [1] 1.2 3.4 4.5 Seleccionar el caso (fila) 2: mi_df [2,] ## variable1 variable2 variable3 variable4 ## 2 2 3.4 b 2 Seleccionar el elemento que se encuentra en la fila 2 y la columna 2: mi_df [2,2] ## [1] 3.4 1.2.8 Nuestras herramientas: Paquetes y funciones PAQUETES En R, un paquete es un conjunto de herramientas y funciones predefinidas que permiten a los usuarios realizar tareas específicas, como análisis de datos o visualización de gráficos. Los paquetes pueden ser instalados desde los repositorios de CRAN u otros lugares (como repositorios). Para instalar un paquete necesitas escribir install.packages(\"nombre_del_paquete\"). Luego de instalarlo, para comenzar a utilizarlo debes abrirlo con el siguiente comando library(nombre_del_paquete). FUNCIONES Las funciones son bloques de código que realizan una tarea específica. Pueden ser definidas por el usuario o pueden ser proporcionadas por un paquete (esto es lo más común). Las funciones toman argumentos, que son valores que se pasan a la función para que los utilice en su tarea. Los argumentos de una función son variables o valores que se pasan a la función para que sean utilizados en la tarea que se está realizando. Algunos argumentos son obligatorios, lo que significa que deben ser proporcionados para que la función pueda realizar su tarea, mientras que otros son opcionales y tienen un valor predeterminado si no se especifican. Para ver qué argumentos tiene una función puedes entrar a la documentación de la misma. Por ejemplo, el paquete “dplyr” es un conjunto de herramientas que se utiliza para manipular y transformar datos en R. Una de las funciones de “dplyr” es “filter”, que se utiliza para filtrar filas en un conjunto de datos. Un argumento obligatorio para la función “filter” es el conjunto de datos que se va a filtrar, mientras que un argumento opcional es la condición que se utilizará para filtrar los datos. 1.3 Importación y exploración de datos En la práctica tenemos el reto de manipular bases de datos que se encuentran en distintos tipos de archivo. Algunas veces se encuentran en formato .xlsx (Excel regular), pero otras veces las encontramos en formato .csv (separado con comas o puntos y comas), .sav (archivos desde el SPSS), entre otros. Para ello, tenemos dos opciones. La más sencilla es utilizar el paquete rio y utilizamos la función import(). Este paquete es una navaja suiza porque te permite abrir distintos formatos con la misma función. library(rio) ## The following rio suggested packages are not installed: &#39;arrow&#39;, &#39;feather&#39;, &#39;fst&#39;, &#39;hexView&#39;, &#39;pzfx&#39;, &#39;readODS&#39;, &#39;rmatio&#39; ## Use &#39;install_formats()&#39; to install them elecciones_2011&lt;-import(&quot;RESULTADOS_EG_PRESIDENCIAL_2011.xls&quot;) head(elecciones_2011,3) ## UBIGEO DEPARTAMENTO PROVINCIA DISTRITO ## 1 010101 AMAZONAS CHACHAPOYAS CHACHAPOYAS ## 2 010101 AMAZONAS CHACHAPOYAS CHACHAPOYAS ## 3 010101 AMAZONAS CHACHAPOYAS CHACHAPOYAS ## ORGANIZACIÓN_POLITICA VOTOS_VALIDOS_OP VOTOS_VALIDOS ## 1 FUERZA NACIONAL 6 11148 ## 2 PARTIDO POLITICO ADELANTE 24 11148 ## 3 DESPERTAR NACIONAL 35 11148 ## VOTOS_BLANCO VOTOS_NULOS NUMERO_ELECTORES VOTOS_EMITIDOS ## 1 1034 340 15748 12522 ## 2 1034 340 15748 12522 ## 3 1034 340 15748 12522 O también podemos utilizar el paquete readxl() que pertenece al universo de Tidyverse. Lo bueno de esta función es que cuando visualizas la data se realiza de forma más ordenada. library(readxl) elecciones_2011&lt;-read_excel(&quot;RESULTADOS_EG_PRESIDENCIAL_2011.xls&quot;) head(elecciones_2011,3) ## # A tibble: 3 × 11 ## UBIGEO DEPARTAMENTO PROVINCIA DISTRITO ORGANIZACIÓN_POLITICA ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 010101 AMAZONAS CHACHAPOYAS CHACHAPOYAS FUERZA NACIONAL ## 2 010101 AMAZONAS CHACHAPOYAS CHACHAPOYAS PARTIDO POLITICO ADELA… ## 3 010101 AMAZONAS CHACHAPOYAS CHACHAPOYAS DESPERTAR NACIONAL ## # ℹ 6 more variables: VOTOS_VALIDOS_OP &lt;dbl&gt;, VOTOS_VALIDOS &lt;dbl&gt;, ## # VOTOS_BLANCO &lt;dbl&gt;, VOTOS_NULOS &lt;dbl&gt;, NUMERO_ELECTORES &lt;dbl&gt;, ## # VOTOS_EMITIDOS &lt;dbl&gt; Si deseas utilizar esta segunda forma, puedes aplicar la función read_csv() para archivos separados con comas. Puedes ver las primeras diez filas con: head(elecciones_2011, 10) ## # A tibble: 10 × 11 ## UBIGEO DEPARTAMENTO PROVINCIA DISTRITO ORGANIZACIÓN_POLITICA ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 010101 AMAZONAS CHACHAPOYAS CHACHAPOYAS FUERZA NACIONAL ## 2 010101 AMAZONAS CHACHAPOYAS CHACHAPOYAS PARTIDO POLITICO ADEL… ## 3 010101 AMAZONAS CHACHAPOYAS CHACHAPOYAS DESPERTAR NACIONAL ## 4 010101 AMAZONAS CHACHAPOYAS CHACHAPOYAS GANA PERU ## 5 010101 AMAZONAS CHACHAPOYAS CHACHAPOYAS FONAVISTAS DEL PERU ## 6 010101 AMAZONAS CHACHAPOYAS CHACHAPOYAS JUSTICIA, TECNOLOGIA,… ## 7 010101 AMAZONAS CHACHAPOYAS CHACHAPOYAS FUERZA 2011 ## 8 010101 AMAZONAS CHACHAPOYAS CHACHAPOYAS PARTIDO DESCENTRALIST… ## 9 010101 AMAZONAS CHACHAPOYAS CHACHAPOYAS ALIANZA POR EL GRAN C… ## 10 010101 AMAZONAS CHACHAPOYAS CHACHAPOYAS ALIANZA SOLIDARIDAD N… ## # ℹ 6 more variables: VOTOS_VALIDOS_OP &lt;dbl&gt;, VOTOS_VALIDOS &lt;dbl&gt;, ## # VOTOS_BLANCO &lt;dbl&gt;, VOTOS_NULOS &lt;dbl&gt;, NUMERO_ELECTORES &lt;dbl&gt;, ## # VOTOS_EMITIDOS &lt;dbl&gt; También puedes hacerle click en Environment o colocar: #View(elecciones) 1.3.1 Verificar el tipo de variable Veamos las variables, podemos utilizar la función names(nombre_de_data) names(elecciones_2011) ## [1] &quot;UBIGEO&quot; &quot;DEPARTAMENTO&quot; ## [3] &quot;PROVINCIA&quot; &quot;DISTRITO&quot; ## [5] &quot;ORGANIZACIÓN_POLITICA&quot; &quot;VOTOS_VALIDOS_OP&quot; ## [7] &quot;VOTOS_VALIDOS&quot; &quot;VOTOS_BLANCO&quot; ## [9] &quot;VOTOS_NULOS&quot; &quot;NUMERO_ELECTORES&quot; ## [11] &quot;VOTOS_EMITIDOS&quot; Veamos si el formato es adecuado. str(elecciones_2011) ## tibble [23,958 × 11] (S3: tbl_df/tbl/data.frame) ## $ UBIGEO : chr [1:23958] &quot;010101&quot; &quot;010101&quot; &quot;010101&quot; &quot;010101&quot; ... ## $ DEPARTAMENTO : chr [1:23958] &quot;AMAZONAS&quot; &quot;AMAZONAS&quot; &quot;AMAZONAS&quot; &quot;AMAZONAS&quot; ... ## $ PROVINCIA : chr [1:23958] &quot;CHACHAPOYAS&quot; &quot;CHACHAPOYAS&quot; &quot;CHACHAPOYAS&quot; &quot;CHACHAPOYAS&quot; ... ## $ DISTRITO : chr [1:23958] &quot;CHACHAPOYAS&quot; &quot;CHACHAPOYAS&quot; &quot;CHACHAPOYAS&quot; &quot;CHACHAPOYAS&quot; ... ## $ ORGANIZACIÓN_POLITICA: chr [1:23958] &quot;FUERZA NACIONAL&quot; &quot;PARTIDO POLITICO ADELANTE&quot; &quot;DESPERTAR NACIONAL&quot; &quot;GANA PERU&quot; ... ## $ VOTOS_VALIDOS_OP : num [1:23958] 6 24 35 2971 7 ... ## $ VOTOS_VALIDOS : num [1:23958] 11148 11148 11148 11148 11148 ... ## $ VOTOS_BLANCO : num [1:23958] 1034 1034 1034 1034 1034 ... ## $ VOTOS_NULOS : num [1:23958] 340 340 340 340 340 340 340 340 340 340 ... ## $ NUMERO_ELECTORES : num [1:23958] 15748 15748 15748 15748 15748 ... ## $ VOTOS_EMITIDOS : num [1:23958] 12522 12522 12522 12522 12522 ... Ok, los caracteres están como chr y las variables numéricas como num. "],["análisis-exploratorio-de-datos.html", "Sesión 2 Análisis exploratorio de datos 2.1 Estadísticos descriptivos", " Sesión 2 Análisis exploratorio de datos 2.1 Estadísticos descriptivos "],["visualización-de-datos-con-ggplot2.html", "Sesión 3 Visualización de datos con ggplot2", " Sesión 3 Visualización de datos con ggplot2 "],["introducción-a-la-estadística-inferencial-i.html", "Sesión 4 Introducción a la Estadística Inferencial I 4.1 Objetivo de la sesión 4.2 Fundamentos 4.3 Métodos de estimación 4.4 Ejercicio 1: ENADES 2022", " Sesión 4 Introducción a la Estadística Inferencial I 4.1 Objetivo de la sesión Entender los principios en los que se basa la estadística inferencial. Comprender cómo se calcula un intervalo de confianza de una media. Calcular el intervalo de confianza de una media con la función ciMean(). Visualizar el IC con un gráfico de barras de error. 4.2 Fundamentos 4.2.1 Inferencia La estadística inferencial utiliza la muestra de datos para hacer estimaciones y tomar decisiones acerca de las características de una población. Esto implica la utilización de técnicas y métodos para inferir información sobre la población a partir de la información recopilada en la muestra. Algunas definiciones básicas: Definición Descripción Población Se refiere al conjunto total de individuos, objetos, eventos, medidas o cualquier otra cosa que se quiera estudiar. En estadística inferencial, la población se utiliza como el objeto de estudio, y se busca inferir información sobre ella a partir de la muestra. Muestra Es un subconjunto de la población que se utiliza para hacer inferencias sobre la población en su conjunto. La selección de la muestra debe hacerse de tal forma que represente de manera adecuada las características de la población. Estadístico Es una medida numérica que se utiliza para resumir o describir alguna característica de la muestra. Los estadísticos se calculan a partir de los datos de la muestra y se utilizan para hacer inferencias sobre los parámetros de la población. Parámetro Es una medida numérica que describe alguna característica de la población. En estadística inferencial, el objetivo es hacer inferencias sobre los parámetros de la población a partir de los datos de la muestra. 4.2.2 La desviación estándar La desviación estándar es una parte integral de la estadística inferencial y entender su funcionamiento nos ayudará a utilizarla más adelante. Recuerda, la desviación estándar es la raíz cuadrada de la sumatoria de todas las diferencias entre los valores observados y su media. \\[\\sigma = \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N}(x_i - \\mu)^2}\\] La desviación estándar se llama “estándar” porque proporciona una unidad de medida común para comparar unidades observadas de medida muy diferente. Ejemplo: imaginemos que tenemos la variable ingreso que tiene media 120 y desviación estándar 10 y deseamos analizar el caso X = 130. Forma de puntuación Fórmula Ejemplo Puntuación en bruto \\[X\\] 130 soles Puntuación de desviación \\[X - \\bar{X}\\] 10 soles Puntuación estandarizada Z \\[Z = \\frac{X - \\bar{X}}{S_X}\\] 1 SD Presta atención a las unidades de medida! En el ejemplo anterior podemos corroborar que nosotros podemos medir la lejanía de una observación respecto a su media, no sólo en las unidades originales, sino diciendo cuántas desviaciones estándar la separa de su media. Está última medida se conoce como puntuaciones Z y es muy útil para comparar niveles de dispersión de variables observadas. Algunas reglas: 1) mientras más lejana esté una observación de su media, mayor será su puntuación de desvación y su puntuación Z. 2) El signo de la puntuación Z indica si la observación está por debajo o por encima de la media. 4.2.3 Distribución normal Anteriormente te comenté que la curva normal (forma de campana) ejercía un rol fundamental en el contexto de la estadística inferencial. Esto es gracias a una propiedades muy interesantes. La principal: cuando una variable tiene distribución de puntuaciones que es normal (casi) la totalidad de observaciones están distribuidas +- 3 desviaciones estándar (puntuaciones Z) respecto de su media. Este principio matemático sienta las bases de la imaginación estadística, dado que muchos fenómenos naturales poseen distribuciones de frecuencias en forma de campana como la curva normal. Como se ve en la figura, son 4 los principios: 1) 50% de las puntuaciones caen encima de la media y 50% debajo; 2) Prácticamente todas las puntuaciones caen dentro de 3 SD a partir de la media en ambas direcciones (en realidad el 99.7%); 3) Cerca del 95% de las puntuaciones de una variable normalmente distribuida caen dentro de una distancia de +- 2 SD respecto de la media; y 4) Alrededor del 68% de las puntuaciones caen dentro de una distancia de +-1 SD respecto de la media. 4.2.4 Teorema del límite central El teorema del límite central (TLC) es uno de los conceptos más importantes de la estadística y es fundamental en el muestreo y la inferencia estadística. En términos simples, el teorema del límite central dice que si tomamos suficientes muestras aleatorias grandes de una población, la distribución de las medias de esas muestras será una distribución normal, sin importar cómo se vea la distribución original de la población. Esto es importante en el muestreo porque nos permite hacer inferencias precisas sobre una población, incluso si no conocemos su distribución. Si podemos asumir que la distribución de la población es aproximadamente normal, entonces podemos usar la distribución normal de las medias de las muestras para hacer predicciones y estimaciones precisas sobre la población. Además, el TLC nos permite calcular intervalos de confianza y realizar pruebas de hipótesis (siguiente secciòn) con mayor precisión, lo que nos permite tomar decisiones más informadas basadas en los datos muestrales. En resumen, el teorema del límite central es una herramienta clave en la inferencia estadística y nos permite hacer generalizaciones precisas sobre una población a partir de datos muestrales. Máquina de Galton El Tablero de Galton ilustra cómo la distribución de frecuencias de los resultados de muchos eventos aleatorios independientes se acerca a una distribución normal, independientemente de la forma de la distribución original, siempre que el número de eventos sea lo suficientemente grande. 4.2.5 Ley de los grandes números La ley de los grandes números es un teorema en estadística que establece que, a medida que el tamaño de una muestra aumenta, la media muestral se acerca a la media poblacional. En otras palabras, cuando se toman muestras cada vez más grandes de una población, se espera que la media de esas muestras se acerque cada vez más a la media real de la población. Esta ley es importante porque permite a los investigadores obtener estimaciones precisas de los parámetros de una población a partir de una muestra relativamente pequeña. Además, esta ley también es fundamental para la teoría de la probabilidad y es utilizada en muchas áreas de la estadística y de la ciencia en general. Mientras más grande sea la muestra, la media muestras se acerca a la media poblacional. 4.2.6 Varias muestras Cuando extraemos varias muestras de una población y calculamos la media para cada una de esas muestras, obtenemos una variedad de medias muestrales. Aunque cada muestra es única y puede tener su propia media, si repitiéramos este proceso de muestreo muchas veces, observaríamos que la distribución de estas medias muestrales tiende a adoptar una forma específica. Esta forma es lo que conocemos como la “distribución de muestreo de la media”. El Teorema del Límite Central, uno de los pilares fundamentales de la estadística inferencial, nos dice que, independientemente de la forma de la distribución original de la población, la distribución de las medias muestrales se aproximará a una distribución normal (o gaussiana) a medida que el tamaño de la muestra aumenta. Esta distribución normal centrada en la media verdadera de la población y con una desviación estándar llamada “error estándar” nos permite hacer inferencias sobre la media poblacional a partir de las medias de nuestras muestras, especialmente cuando el tamaño de la muestra es grande. 4.2.7 Error estándar El error estándar es una medida que nos indica cuánto esperamos que varíe una estadística (como la media o la proporción) de una muestra a otra, si tomáramos múltiples muestras de la misma población. En otras palabras, es una forma de medir la variabilidad que se espera en nuestras estimaciones debido al hecho de que estamos trabajando con muestras y no con la totalidad de la población. Podríamos pensar en el error estándar como una herramienta que nos ayuda a entender cuán “confiables” o “precisas” son nuestras estimaciones basadas en muestras. Un error estándar pequeño sugiere que nuestras estimaciones son relativamente estables y consistentes de una muestra a otra, mientras que un error estándar grande indica que esas estimaciones podrían variar considerablemente entre diferentes muestras. Es importante destacar que el error estándar está relacionado con la desviación estándar de la población. Mientras que la desviación estándar nos dice cuánto varían los valores individuales alrededor de la media en una población o muestra, el error estándar nos dice cuánto esperamos que varíen nuestras estadísticas de muestra (como la media muestral) alrededor de la verdadera estadística poblacional. Recuerdas que habíamos dicho que en la curva normal se podría evidenciar que la totalidad de las observaciones se encontraban entre -3 y +3 desviaciones estándar respecto de la media? En el caso de las distribuciones muestrales, esa desviación estándar es conocida como error estándar. El error estándar mide la dispersión del error de muestreo que ocurre cuando se muestrea repetidamente una población (como lo hicimos líneas arriba). \\[s_{\\hat{x}} = \\frac{s}{\\sqrt{n}}\\] Entonces los puntos más importantes del EE son: El error estándar es una medida de cuánto se espera que varíen las medias de las muestras tomadas de una población determinada. A medida que el tamaño de la muestra aumenta, el error estándar tiende a disminuir. El error estándar es importante en el cálculo de los intervalos de confianza. Cuanto menor sea el error estándar, menor será la variabilidad de las medias muestrales y más preciso será el intervalo de confianza. El error estándar se calcula dividiendo la desviación estándar de la población entre la raíz cuadrada del tamaño de la muestra. En la mayoría de los casos, la desviación estándar de la población no se conoce y se utiliza la desviación estándar de la muestra para estimar el error estándar. 4.3 Métodos de estimación 4.3.1 Estimación puntual En estadística inferencial, la estimación puntual se refiere a la técnica de utilizar los datos de una muestra para calcular un único valor, conocido como punto estimado, que es la mejor suposición o predicción del valor de un parámetro desconocido de la población. Por ejemplo, si queremos conocer el salario promedio de todos los trabajadores de una empresa, podríamos tomar una muestra aleatoria de trabajadores, calcular el salario promedio de esa muestra y usar ese valor como nuestra estimación puntual del salario promedio real de toda la empresa. Esencialmente, este valor es nuestra “mejor suposición” basada en la información que hemos recolectado. Sin embargo, aunque la estimación puntual es directa y fácil de entender, no refleja la incertidumbre o variabilidad que podría haber en esa estimación. Es por esta razón que, en muchas situaciones, se complementa con técnicas como la estimación por intervalo para obtener una visión más completa y matizada del parámetro que estamos tratando de estimar. 4.3.2 Intervalo de confianza de una media El intervalo de confianza es un rango de valores posibles de un parámetro expresado con un grado específico de confianza. Si tenemos un nivel de confianza de 95% quiere decir que si realizamos 100 veces el mismo procedimiento de muestreo y calculamos los estadísticos de interés, 95 veces nos van a salir resultados en los intervalos calculados. Si lo realizamos con un 99% de confianza, de igual manera, si realizamos 100 veces el procedimiento, 99 veces nos va a salir resultados en el intervalo resultante. Esto lo tenemos claro gracias a la explicación del rol que cumple la curva normal y sus propiedades. A MAYOR CONFIANZA MENOR ES LA PRECISIÓN (LOS INTERVALOS SON MÁS AMPLIOS) Para el cálculo de un intervalo de confianza utilizamos la siguiente fórmula. Recuerda - Ese valor que se suma y se resta a la media muestral es el término de error, sin embargo, es más conocido como margen de error. 4.4 Ejercicio 1: ENADES 2022 El Instituto de Estudios Peruanos, por encargo de Oxfam en Perú, elaboró la I Encuesta Nacional de percepción de Desigualdades – ENADES 2022. Este estudio pone a disposición del público el análisis estadístico más completo a la fecha sobre la percepción de las diferentes formas de desigualdad en el Perú. Además de factores económicos, la presente encuesta incluye indicadores que permiten medir la magnitud de una serie de brechas sociales y políticas: desde diferencias de género, clase y relaciones étnico-raciales, hasta dimensiones subjetivas de la desigualdad y sus vínculos con orientaciones políticas. Como se muestra a lo largo del informe, la base de datos de este proyecto provee herramientas valiosas a expertos de diferentes campos, tanto académicos como profesionales, estudiantes y personas interesadas en el análisis multidimensional de la desigualdad en el país. Puedes abrir el cuestionario de la encuestas aquí. También puedes ver el informe aquí. 4.4.1 Abrir base de datos library(haven) library(tidyverse) enades&lt;-read_spss(&quot;data/ENADES_2022.sav&quot;) # Con esta función abrimos archivos de SPSS # enades&lt;-read_spss(&quot;https://github.com/ChristianChiroqueR/banco_de_datos/raw/main/ENADES_2022.sav&quot;) names(enades) ## [1] &quot;NC&quot; &quot;edad&quot; &quot;edadr&quot; &quot;sexo&quot; ## [5] &quot;dep&quot; &quot;prov&quot; &quot;dist&quot; &quot;zona1&quot; ## [9] &quot;zona2&quot; &quot;zona3&quot; &quot;zonali1&quot; &quot;zonali2&quot; ## [13] &quot;region&quot; &quot;area&quot; &quot;area2&quot; &quot;ambito&quot; ## [17] &quot;hijos18&quot; &quot;hogar&quot; &quot;edu&quot; &quot;edur&quot; ## [21] &quot;edu2&quot; &quot;edupadre&quot; &quot;edupadrer&quot; &quot;edupadre2&quot; ## [25] &quot;edumadre&quot; &quot;edumadrer&quot; &quot;edumadre2&quot; &quot;ocup1&quot; ## [29] &quot;ocup2.CIUO1&quot; &quot;ocup2.CIUO2&quot; &quot;ocupadre&quot; &quot;p01.1&quot; ## [33] &quot;p01.2&quot; &quot;p01.3&quot; &quot;p01.4&quot; &quot;p01.5&quot; ## [37] &quot;p01.99&quot; &quot;p02&quot; &quot;p03.1&quot; &quot;p03.2&quot; ## [41] &quot;p03.3&quot; &quot;p03.4&quot; &quot;p03.5&quot; &quot;p04&quot; ## [45] &quot;p04a&quot; &quot;p05&quot; &quot;p06&quot; &quot;p07&quot; ## [49] &quot;p07a&quot; &quot;p08&quot; &quot;yhogar&quot; &quot;yhogar_pc1&quot; ## [53] &quot;yhogar_pc2&quot; &quot;ABq10d&quot; &quot;p10.1&quot; &quot;p10.2&quot; ## [57] &quot;p10.3&quot; &quot;p10.4&quot; &quot;p10.5&quot; &quot;p10.6&quot; ## [61] &quot;p10.7&quot; &quot;p11.1&quot; &quot;p11.2&quot; &quot;p11.3&quot; ## [65] &quot;p11.4&quot; &quot;p12.1&quot; &quot;p12.2&quot; &quot;p12.3&quot; ## [69] &quot;p12.4&quot; &quot;ABros1&quot; &quot;ABros6&quot; &quot;ABros4&quot; ## [73] &quot;p13&quot; &quot;p14_1&quot; &quot;p14_2&quot; &quot;p14_3&quot; ## [77] &quot;p15&quot; &quot;p16&quot; &quot;p17&quot; &quot;etnicidad&quot; ## [81] &quot;etnicidad2&quot; &quot;ideología&quot; &quot;ideologia2&quot; &quot;NSE&quot; ## [85] &quot;NSE1&quot; &quot;NSE2&quot; &quot;pondera&quot; Recuerda que si en un primer momento te pierdes un poco entre los nombres de las variables, eso quiere decir que tienes que leer el cuestionario y el diccionario de variables! 4.4.2 Identificar una variable numérica Elijamos la variable P17: En una escala del 1 al 10, en la que 1 es “Totalmente inaceptable” y 10 es “Totalmente aceptable”. ¿Hasta qué punto es aceptable la desigualdad en el Perú? Dígame un número de 1 a 10, recuerde que 1 es “Totalmente inaceptable” y 10 es “Totalmente aceptable (RESPUESTA ESPONTÁNEA) La convertimos en numérica. enades$p17&lt;-as.numeric(enades$p17) Solicitamos los estadísticos descriptivos para darle una primera mirada. summary(enades$p17) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 1.000 1.000 5.000 4.571 7.000 10.000 23 Podemos graficarlo enades |&gt; ggplot() + aes(x=p17)+ geom_bar() 4.4.3 Cálculo del estimador puntual Calculamos el estimador puntual, en este caso, la media muestral. mean(enades$p17, na.rm = TRUE) ## [1] 4.571334 Tienes que recordar lo básico de este: Es solo una aproximación del verdadero valor poblacional, y su precisión puede variar dependiendo del tamaño y calidad de la muestra, entre otros factores. Es por ello que, a menudo, se complementa con intervalos de confianza para ofrecer un rango de valores en los que es probable que se encuentre el verdadero parámetro poblacional. 4.4.4 Cálculo del IC al 95% MANUAL Recordemos qué necesitamos para calcular el intervalo de confianza de una media. Necesitamos la media muestral (mean) de esa única muestra que obtuvimos de la población, la desviación estándar (sd) y el tamaño de muestra que tenemos (n). Así también, necesitamos elegir qué nivel de confianza vamos a tomar (recuerdas los intervalos de la distribución normal? y cómo se aplicaría a distribuciones muestrales?), es decir, si vamos al 95% (1.96) o algún otro nivel. Calculemos cada uno de estos media&lt;-mean(enades$p17, na.rm = TRUE) SE&lt;- sd(enades$p17, na.rm = TRUE) n &lt;-length(enades$p17) z&lt;- 1.96 Ahora recordamos la fórmula: Dónde el error estándar está dado por: \\[s_{\\hat{x}} = \\frac{s}{\\sqrt{n}}\\] Entonces: error_estandar &lt;- SE/sqrt(n) error_estandar ## [1] 0.08009848 Por lo pronto, hemos obtenido un error estándar con un valor de 0.08009848. El error estándar, en su esencia, nos brinda una medida de cuánta variabilidad podemos esperar en nuestras estimaciones si repitiéramos el muestreo muchas veces. Cuando interpretamos un error estándar específico, como 0.08009848podemos considerar lo siguiente: Un error estándar de 0.08009848 sugiere que, si tomáramos múltiples muestras del mismo tamaño de la población y calculáramos la estadística de interés (por ejemplo, la media) para cada muestra, esperaríamos que la mayoría de esas estadísticas estuvieran dentro de 0.08009848 unidades de la estadística media de todas esas muestras. En otras palabras, el valor de 0.08009848 nos da una idea de la “precisión” de nuestra estimación basada en una sola muestra. Una estimación con un error estándar más pequeño generalmente se considera más “precisa” que una con un error estándar más grande, porque indica menos variabilidad entre las estimaciones de diferentes muestras. Ahora sí, una vez calculado el error estándar podemos calcular los límite inferior o superior. Recuerda que debemos aplicar la fórmula y que la única diferencia para calcular el límite inferior y superior es el signo: limite_inferior&lt;- media - (z*error_estandar) limite_superior&lt;- media + (z*error_estandar) Los presentamos: limite_inferior ## [1] 4.414341 limite_superior ## [1] 4.728327 Con ello podemos concluir que: Con un 95% de confianza, podemos afirmar que la media poblacional de la aceptación de la desigualdad en el Perú (que va del 1 al 10) se encuentra entre 4.414341 y 4.728327. Esto lo podemos interpretar también de las siguientes forma: Estoy 95% seguro de que el promedio de aceptación de la desigualdad en el país real (es decir el parámetro) se encuentra entre 4.414341 y 4.728327. Si realizara este estudio 100 veces, 95 veces obtendré un promedio de aceptación de la desigualdad dentro de este intervalo: 4.414341 y 4.728327. CON LA FUNCIÓN ciMean() Una vez que hemos navegado por el proceso de calcular un intervalo de confianza de manera manual, utilizando la fórmula tradicional, es hora de introducir herramientas que simplifiquen y agilicen este proceso en el mundo real del análisis de datos. Para ello, en R, utilizaremos el paquete lsr y, específicamente, la función ciMean. Esta función está diseñada para calcular automáticamente el intervalo de confianza para la media de un conjunto de datos. Al proporcionarle una serie de datos como entrada, ciMean nos devuelve el rango en el que, con un nivel de confianza específico (por defecto, 95%), esperamos que se encuentre la verdadera media poblacional. Es una herramienta poderosa que combina precisión con eficiencia, permitiéndonos centrarnos en la interpretación y aplicación de nuestros resultados. library(lsr) ciMean(enades$p17, na.rm = T) ## 2.5% 97.5% ## [1,] 4.413023 4.729645 Es el mismo resultado que obtuvimos arriba. Como te puedes dar cuenta, si hemos recorrido este camino (medio tedioso) es para que te quede claro cómo se obtienen esos dos números que llamamos intervalos de confianza y de qué depende en la práctica al utilizar una muestra real. 4.4.5 Barras de error Tras calcular el intervalo de confianza, una práctica recomendada es visualizarlo gráficamente. El representar este intervalo en un gráfico no solo nos facilita la comprensión de su significado, sino que también nos proporciona una perspectiva visual de dónde se sitúa nuestra estimación y el rango dentro del cual esperamos que se encuentre el verdadero valor poblacional. Al observar el intervalo de confianza en un gráfico, podemos tener una idea más intuitiva y clara de la precisión y confiabilidad de nuestra estimación, así como de la variabilidad asociada a ella. En el contexto de intervalos de confianza, las barras de error se utilizan para representar el nivel de incertidumbre en una estimación puntual del parámetro poblacional. Un intervalo de confianza es un rango de valores plausible para el valor del parámetro poblacional, y se construye a partir de una muestra aleatoria y un nivel de confianza específico. Las barras de error en un gráfico de intervalos de confianza se construyen a partir de los límites superior e inferior del intervalo de confianza. Generalmente se dibujan líneas verticales que se extienden desde el valor estimado del parámetro (que puede ser una media, una proporción, una diferencia de medias, etc.) hasta los límites del intervalo de confianza. Por ejemplo, si se estima la media de una variable a partir de una muestra y se desea construir un intervalo de confianza al 95%, las barras de error se construirán a partir del límite inferior y superior del intervalo de confianza, que contendrán el verdadero valor de la media poblacional con una probabilidad del 95%. Las barras de error en un gráfico de intervalos de confianza pueden ser útiles para comparar la precisión de las estimaciones entre diferentes grupos o condiciones. Si las barras de error son muy pequeñas, esto sugiere que la estimación es muy precisa y que hay una alta confianza en la validez del intervalo de confianza. Por otro lado, si las barras de error son grandes, esto sugiere que la estimación es menos precisa y que hay una mayor incertidumbre en el intervalo de confianza. Podemos utilizar ggplot()! mediaEintervalos&lt;-enades %&gt;% summarise(mean = mean(p17, na.rm = TRUE), #Utilizamos summarise y pedimos la media, ci_lower = ciMean(p17, na.rm = T)[1], # También el PRIMER ELEMENTO de la función ciMean ci_upper = ciMean(p17, na.rm = T)[2]) #Y el SEGUNDO ELEMENTO de la función ciMean mediaEintervalos ## # A tibble: 1 × 3 ## mean ci_lower ci_upper ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 4.57 4.41 4.73 mediaEintervalos %&gt;% ggplot() + aes(x = &quot;Media&quot;, y = mean)+ geom_point(size = 3) + geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0.2) + labs(title = &quot;Media de aceptación de la desigualdad en el Perú (IC al 95%)&quot;, y = &quot;Valor&quot;, x = &quot;&quot;) Puedes incluir más detalle y detallar los límites inferior y superior: mediaEintervalos %&gt;% ggplot() + aes(x = &quot;Media&quot;, y = mean) + geom_point(size = 3) + geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0.2) + geom_text(aes(label = round(ci_lower, 3), y = ci_lower), vjust = 1.5, hjust = -0.5) + # Etiqueta para el límite inferior geom_text(aes(label = round(ci_upper, 3), y = ci_upper), vjust = -0.5, hjust = -0.5)+ # Etiqueta para el límite superior labs(title = &quot;Media de aceptación de la desigualdad en el Perú (IC al 95%)&quot;, y = &quot;Valor&quot;, x = &quot;&quot;) "],["ic-para-una-media-y-una-proporción-ic-entre-grupos.html", "Sesión 5 IC para una media y una proporción, IC entre grupos 5.1 Objetivo de la sesión. 5.2 Índice Aditivo 5.3 Intervalos de confianza para grupos 5.4 Ejercicio 1 5.5 Ejercicio 2 5.6 Intervalo de una proporción 5.7 Ejercicio 3", " Sesión 5 IC para una media y una proporción, IC entre grupos 5.1 Objetivo de la sesión. Comprender qué es un índice aditivo y cómo se utiliza como medida resumen. Calcular el IC del índice para toda la población y entre grupos. Visualizar el IC del Índice entre grupos. 5.2 Índice Aditivo Un índice aditivo es una técnica utilizada en la investigación social y otras áreas para combinar múltiples indicadores o variables en una única medida compuesta. La idea central detrás de un índice aditivo es sumar las puntuaciones o valores de diferentes ítems para obtener un puntaje total que represente una característica o concepto más amplio que no se puede medir directamente con un solo ítem. Supongamos que realizas una encuesta y pides a los encuestados que evalúen su satisfacción con los servicios públicos de agua, luz y desagüe utilizando una escala Likert de 1 (muy insatisfecho) a 5 (muy satisfecho). Ahora, deseas combinar estas tres variables en un índice aditivo que mida la satisfacción general con los servicios públicos. Paso 1: Obten los datos Por ejemplo, un encuestado ha contestado: Agua: 4 Luz: 5 Desagüe: 3 Paso 2: Creación del índice aditivo Para crear el índice, simplemente sumarías las puntuaciones de estas tres variables: Índice de Satisfacción = Agua + Luz + Desagüe Índice de Satisfacción = 4 + 5 + 3 = 12 El puntaje total para este encuestado en el índice de satisfacción con los servicios públicos sería 12. Dado que estás utilizando una escala Likert de 1 a 5 y tres servicios, el puntaje máximo posible para el índice sería 15 (si estuvieran muy satisfechos con los tres servicios) y el mínimo sería 3 (si estuvieran muy insatisfechos con los tres servicios). Paso 3: Estandarización Reescalar es el proceso de ajustar el rango de una variable para que se ajuste a una nueva escala. En el contexto de nuestro índice de satisfacción con los servicios públicos, reescalar los datos a una escala de 0 a 10 puede tener varias ventajas. Primero, una escala de 0 a 10 es intuitivamente comprensible para la mayoría de las personas, ya que es similar a las escalas que a menudo se utilizan en educación para calificar el desempeño. Segundo, al tener un rango definido, facilita la interpretación y comparación de los resultados. Por ejemplo, un valor de 8 en esta escala sugiere una alta satisfacción, mientras que un valor cercano a 0 indica insatisfacción. Finalmente, reescalar a una escala estándar como 0 a 10 puede facilitar la comparación con otros índices o estudios que utilicen la misma escala, permitiendo una evaluación más uniforme y coherente. Para ello, podemos utilizar el paquete scales y específicamente la función `rescale()`` Paso 4: Describir Una vez reescalado, el índice se convierte en un resumen efectivo de las variables originales, consolidando la información en una única medida. Esta representación condensada facilita su uso en análisis posteriores. Por ejemplo, podemos obtener intervalos de confianza para el índice, proporcionando un rango de valores en el que es probable que se encuentre la verdadera media poblacional. Además, el índice reescalado puede ser utilizado en diversos modelos estadísticos, análisis de tendencias o incluso comparaciones entre diferentes grupos o períodos de tiempo, ofreciendo una herramienta versátil para la investigación y toma de decisiones. 5.3 Intervalos de confianza para grupos El intervalo de confianza de una media en grupos brinda un rango estimado para la verdadera media poblacional dentro de categorías específicas o subconjuntos de datos, siendo crucial en análisis sociopolíticos. En lugar de un solo intervalo para toda una población, se calcula un intervalo para cada grupo de interés político o social. Permite realizar comparaciones detalladas entre distintos grupos sociopolíticos o demográficos. Su utilidad en ciencia política y ciencias sociales incluye: Evaluación de la aprobación de líderes políticos entre diferentes grupos demográficos (por ejemplo, por edad, género o nivel educativo), análisis de tendencias electorales en diferentes regiones o entre distintos grupos socioeconómicos, estudio de la percepción pública sobre políticas específicas, como reformas educativas o de salud, entre diferentes sectores de la población, comparación de niveles de confianza en instituciones gubernamentales entre urbanos y rurales o entre diferentes grupos étnicos, entre otros. Es esencial para entender las dinámicas y divisiones dentro de una sociedad, identificando posibles brechas o áreas de consenso. En resumen, es una herramienta vital para académicos, analistas y tomadores de decisiones en ciencia política, permitiendo un análisis más profundo y matizado de las actitudes y percepciones públicas. Para nuestros fines, nos alejaremos un poco de la fórmula que vimos la clase pasada y lo haremos todo mucho más rápido con la utilización de la función ciMean(). 5.4 Ejercicio 1 5.4.1 Pregunta de investigación En base a la data ENADES, calcule un índice aditivo de Percepción sobre la desigualdad en el acceso a servicios públicos. Para ello, vamos a utilizar estas cuatro variables: Brinde el intervalo de confianza de la media de percepción sobre la desigualdad en el acceso a servicios públicos en la población al 95% Asimismo, genere una comparación de los intervalos de confianza para los sectores de “Lima Metropolitana” y “Perú sin Lima” (según variable zona3) ABRIMOS LA DATA library(haven) library(tidyverse) library(lsr) library(kableExtra) ## ## Attaching package: &#39;kableExtra&#39; ## The following object is masked from &#39;package:dplyr&#39;: ## ## group_rows enades&lt;-read_spss(&quot;https://github.com/ChristianChiroqueR/banco_de_datos/raw/main/ENADES_2022.sav&quot;) 5.4.2 Creamos el índice aditivo Paso 1: Verificar que las variables corresponden al concepto En este caso las tres se destinan a medir una percepción en relación a la desigualdad de la entrega de un servicio por parte del Estado. Paso 2: Revisar el sentido de las categorías en el cuestionario/diccionario Antes de sumar las variables individuales para crear un índice aditivo, es esencial verificar la estructura y la coherencia de las categorías en las escalas de las variables que se combinarán. Las categorías de cada escala deben alinearse de manera que el progreso a través de las categorías refleje una progresión lógica y uniforme en la variable subyacente. Por ejemplo, si estamos evaluando la satisfacción con ciertos servicios, las categorías de la escala deberían estructurarse de manera que un número más alto indique una mayor satisfacción, mientras que un número más bajo denota menos satisfacción. Esto asegura que el índice sea intuitivo: a medida que el valor del índice aumenta, también lo hace la intensidad o el grado de la característica que se está midiendo. Al garantizar que las categorías de la escala estén bien alineadas y sean intuitivas, nos aseguramos de que el índice aditivo resultante sea válido y refleje de manera precisa el constructo que intentamos medir. En este caso vemos que las variables tienen las siguientes escalas: (1) Muy desigual, (2) Poco desigual y (3) Nada desigual. Ciertamente, sería más intuitivo si el 3 indicaría “mucha desigualdad” y el 1 “poca desigualdad” #Percepción de desigualdad en el acceso a la educación #summary(enades$p11.1) table(enades$p11.1) ## ## 1 2 3 ## 912 503 80 #Percepción de desigualdad en el acceso a la salud #summary(enades$p11.2) table(enades$p11.2) ## ## 1 2 3 ## 1080 361 56 #Percepción de desigualdad en el acceso al trabajo #summary(enades$p11.3) table(enades$p11.3) ## ## 1 2 3 ## 885 544 56 #Percepción de desigualdad el acceso a la justicia #summary(enades$p11.4) table(enades$p11.4) ## ## 1 2 3 ## 1274 170 48 En el mundo de la investigación y el análisis de datos, la exploración descriptiva inicial es una etapa crucial que no debe pasarse por alto. Esta exploración nos permite comprender la estructura, la distribución y las características generales de nuestros datos antes de realizar análisis más complejos. Una de las razones más importantes para llevar a cabo esta fase exploratoria es la detección de valores atípicos o inusuales, incluidos los valores codificados como “No sabe/No responde” (NS/NR), que a menudo se representan con códigos numéricos específicos como 999, 888, entre otros. Cuando no se detectan o se manejan adecuadamente, estos valores codificados como NS/NR pueden introducir errores significativos en nuestros análisis. Por ejemplo, si se incluyen en el cálculo de una media, estos valores altos (como 999) inflarán artificialmente la media, resultando en una representación imprecisa de la tendencia central de los datos. Además, estos valores pueden distorsionar otros cálculos y estadísticas descriptivas, como la mediana, la varianza, y el rango. En el contexto de ciencias sociales y ciencia política, donde las encuestas y los cuestionarios son herramientas comunes, los valores de NS/NR son habituales. Los encuestados pueden no querer, o no saber, cómo responder a ciertas preguntas. Es esencial identificar y manejar adecuadamente estos valores para garantizar que los resultados del análisis sean válidos y representativos de la población en estudio. Por lo tanto, una exploración descriptiva cuidadosa es el primer paso crucial para garantizar la integridad y precisión de cualquier análisis posterior. Como corroboramos que no hay problema de este tipo vamos a recodificar las variables para volverlas intuitivas. enades&lt;-enades |&gt; mutate(p11.1n=case_when(p11.1==1~3, p11.1==2~2, p11.1==3~1, TRUE~NA_real_), p11.2n=case_when(p11.2==1~ 3, p11.2==2~2, p11.2==3~1, TRUE~NA_real_), p11.3n=case_when(p11.3==1~ 3, p11.3==2~2, p11.3==3~1, TRUE~NA_real_), p11.4n=case_when(p11.4==1~ 3, p11.4==2~2, p11.4==3~1, TRUE~NA_real_)) table(enades$p11.1n) ## ## 1 2 3 ## 80 503 912 table(enades$p11.2n) ## ## 1 2 3 ## 56 361 1080 table(enades$p11.3n) ## ## 1 2 3 ## 56 544 885 table(enades$p11.4n) ## ## 1 2 3 ## 48 170 1274 Paso 3: Creación del índice aditivo (sumar) Ahora sí podremos realizar el índice aditivo. enades&lt;-enades |&gt; mutate(indice_aditivo=p11.1n+p11.2n+p11.3n+p11.4n) #Creamos una nueva variable que es la suma de las originarias recodificadas. enades |&gt; count(indice_aditivo) ## # A tibble: 10 × 2 ## indice_aditivo n ## &lt;dbl&gt; &lt;int&gt; ## 1 4 5 ## 2 5 3 ## 3 6 15 ## 4 7 35 ## 5 8 82 ## 6 9 145 ## 7 10 274 ## 8 11 337 ## 9 12 550 ## 10 NA 84 Como nuestras variables de insumo tenían como valores posibles 1-3, nuestro índice tendrá una escala posible de 4 (si la persona contestó a todo con 1) a 12 (si la persona contestó a todo con 3). Paso 4: Estandarización Sobre este índice ya creado, podemos cambiarle la escala para que no sea de 4-12 sino de 0-10. 4A. Esto lo podemos realizar manualmente: 1) Identificamos el valor mínimo y máximo con summary(); 2) Restar a todos los valores el mínimo; 3) Al resultado, dividir por el máximo menos el mínimo; 4) Multiplicar por el número que será el nuevo máximo. Ejemplo: enades %&gt;% mutate(indice_1_10=(indice_aditivo-4)/8*10) %&gt;% # count(indice_1_10) ## # A tibble: 10 × 2 ## indice_1_10 n ## &lt;dbl&gt; &lt;int&gt; ## 1 0 5 ## 2 1.25 3 ## 3 2.5 15 ## 4 3.75 35 ## 5 5 82 ## 6 6.25 145 ## 7 7.5 274 ## 8 8.75 337 ## 9 10 550 ## 10 NA 84 4b. O también con una función (bastante más rápido) library(scales) enades$indice_aditivo_reescalado&lt;-rescale(enades$indice_aditivo, to=c(0,10)) #Aquí mencionas que quieresque la nueva escala sea de 0 al 10. Vemos que el resultado es exactamente el mismo. enades |&gt; count(indice_aditivo_reescalado) ## # A tibble: 10 × 2 ## indice_aditivo_reescalado n ## &lt;dbl&gt; &lt;int&gt; ## 1 0 5 ## 2 1.25 3 ## 3 2.5 15 ## 4 3.75 35 ## 5 5 82 ## 6 6.25 145 ## 7 7.5 274 ## 8 8.75 337 ## 9 10 550 ## 10 NA 84 enades %&gt;% ggplot() + aes(x=indice_aditivo_reescalado)+ geom_bar()+ geom_text(stat=&#39;count&#39;, aes(label=..count..), vjust=-0.5) ## Warning: The dot-dot notation (`..count..`) was deprecated in ggplot2 3.4.0. ## ℹ Please use `after_stat(count)` instead. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this ## warning was generated. ## Warning: Removed 84 rows containing non-finite values (`stat_count()`). ## Removed 84 rows containing non-finite values (`stat_count()`). 5.4.3 Cálculo del intervalo de confianza al 95% Estimación puntual El estimador puntual es una estadística descriptiva que se utiliza para estimar el valor desconocido de un parámetro poblacional a partir de una muestra. El estimador puntual proporciona una única estimación del valor del parámetro y se calcula a partir de los datos de la muestra. En este caso, la mejor estimación de la media población es simplemente la media muestral. mean(enades$indice_aditivo_reescalado, na.rm=TRUE) #Calculamos la media, obviando valores perdidos. ## [1] 8.293568 5.4.4 IC para una media Ahora, una vez identificado el estimador puntual, podemos cambiar nuestra estimación, ahora utilizando intervalos. La clase pasada lo hicimos con la fórmula, paso por paso. Ahora, utilizaremos una función: #library(lsr) #Recuerda que esta función está en el paquete lsr ciMean(enades$indice_aditivo_reescalado, na.rm = T) # Calculamos el intervalo de confianza de p17, obviando valores perdidos. ## 2.5% 97.5% ## [1,] 8.197055 8.390082 5.4.5 IC para una media según grupos Una vez que ya tenemos nuestra variable numérica, lo que necesitamos para comparar es justamente un grupo de comparación. Ya hablando en programación del R, necesitamos un factor. Recuerda que el factor era una variable que visualmente son números, pero teóricamente sabemos que cada número es un nivel. Utilizaremos la variable zona3, la cual separa a los encuestados según su procedencia en: “Lima Metropolitana” y “Perú sin Lima”. Veamos: enades$zona3&lt;-factor(enades$zona3, # Nombre de la variable a convertir levels=1:2, # Definimos los niveles (esta variable sólo tenía 2 niveles) labels=c(&quot;Lima Metropolitana&quot;, &quot;Perú sin Lima&quot;)) #Colocamos sus etiquetas #Con este comando hemos sobreescrito la variable zona3. Ahora lo que inicialmente era una variable numérica, ahora es un factor. Corroboremos: str(enades$zona3) #Solicitamos la estructura de la variable zona3 ## Factor w/ 2 levels &quot;Lima Metropolitana&quot;,..: 1 1 2 2 2 2 2 2 2 2 ... Solicitemos el intervalo de confianza de la variable creada para cada grupo identificado: indice_segun_zona&lt;-enades %&gt;% group_by(zona3) %&gt;% #Agrupamos por zona summarise(mean = mean(indice_aditivo_reescalado, na.rm = TRUE), #Utilizamos summarise y pedimos la media, ci_lower = ciMean(indice_aditivo_reescalado, na.rm = T)[1], # También el PRIMER ELEMENTO de la función ciMean ci_upper = ciMean(indice_aditivo_reescalado, na.rm = T)[2]) #Y el SEGUNDO ELEMENTO de la función ciMean indice_segun_zona ## # A tibble: 2 × 4 ## zona3 mean ci_lower ci_upper ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Lima Metropolitana 8.48 8.33 8.64 ## 2 Perú sin Lima 8.19 8.07 8.31 Según el cálculo, para Lima Metropolitana la media poblacional se encuentra entre 8.49 y 8.77, mientras que para Perú sin Lima se encuentra entre 8.25 y 8.47. INTERPRETACIÓN Al comparar dos intervalos de confianza entre grupos, lo más importante a tener en cuenta son: Superposición de Intervalos: Si los intervalos de confianza de dos grupos no se superponen, esto sugiere una diferencia estadísticamente significativa entre las medias de los grupos en la población. -Posición del Intervalo en la Escala: Aparte de la superposición, es esencial observar dónde se sitúan los intervalos en la escala. Si un grupo tiene un intervalo de confianza que se sitúa consistentemente más alto que el otro, puede indicar una tendencia o dirección en la diferencia entre los grupos. Nivel de Confianza Utilizado y amplitud el intervalo: Es importante recordar el nivel de confianza utilizado al construir los intervalos (por ejemplo, 95%). Un nivel de confianza más alto resultaría en intervalos más amplios, mientras que un nivel más bajo daría como resultado intervalos más estrechos. Aplicando a los resultados precisados: Superposición: No hay. Un intervalo va de 8.49 a 8.77 (Lima Metropolitana) y el otro de 8.25 y 8.47 (Perú sin Lima). Esto sugiere una diferencia estadísticamente significativa entre estos sectores. Posición del intervalo en la escala: Podemos decir que tenemos indicio de que en promedio la percepción de desigualdad en el acceso a servicios es más alta en Lima que en el resto del país. Nivel de confianza: Recordemos, cuando usamos ciMean() estamos utilizando un nivel de confianza del 95% por default. Por ejemplo, cuánto sería los intervalos de confianza al 99%? enades %&gt;% group_by(zona3) %&gt;% summarise(mean = mean(indice_aditivo_reescalado, na.rm = TRUE), ci_lower = ciMean(indice_aditivo_reescalado, na.rm = TRUE, conf = 0.99)[1], ci_upper = ciMean(indice_aditivo_reescalado, na.rm = TRUE, conf = 0.99)[2]) ## # A tibble: 2 × 4 ## zona3 mean ci_lower ci_upper ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Lima Metropolitana 8.48 8.28 8.69 ## 2 Perú sin Lima 8.19 8.03 8.35 Qué puedes observar? 5.4.6 Visualización Como dijimos, las barras de error en un gráfico de intervalos de confianza pueden ser útiles para comparar la precisión de las estimaciones entre diferentes grupos o condiciones. Podemos utilizar un comando básico como la función plotmeans(): library(gplots) plotmeans(enades$indice_aditivo_reescalado~enades$zona3, p=0.95, xlab=&quot;Ámbito&quot;, ylab=&quot;Índice de percepción de desigualdad en acceso a servicios&quot;, main=&quot;Gráfico de medias de Índice Aditivo&quot;) Sin embargo, te recomiendo utilizar ggplot()! indice_segun_zona |&gt; #Data ggplot()+ #Iniciamos el ggplot. A partir de ahora son +! ya no |&gt;! aes(y=mean, x=zona3)+ #Los grupos en el eje X y la media en el eje Y geom_errorbar(aes(ymin=ci_lower, ymax=ci_upper), width=0.2)+ #Graficamos la barra de error geom_text(aes(label=paste(round(mean, 2))), vjust=0, size=5)+ #Colocamos el texto del valor de la media xlab(&quot;Procedencia&quot;) + #Etiqueta del eje X ylab(&quot;Percepción de la desigualdad&quot;) # Etiqueta del eje y RECUERDA: Se superponen los intervalos? Si los intervalos de confianza se superponen significa que no hay una diferencia estadísticamente significativa entre las estimaciones correspondientes a cada intervalo. Es decir, la diferencia entre las estimaciones no es lo suficientemente grande como para ser considerada significativa desde un punto de vista estadístico. IMPORTANTE!! Es importante tener en cuenta que la superposición de los intervalos de confianza no es una prueba concluyente de que no hay una diferencia significativa entre las estimaciones. Se debe realizar una prueba de hipótesis para determinar si la diferencia es estadísticamente significativa o no. Sin embargo, la superposición de los intervalos de confianza puede ser una indicación inicial de que la diferencia no es significativa y que no se debe buscar más evidencia. 5.5 Ejercicio 2 PREGUNTA Utilizando la variable monto mínimo mensual que requiere su hogar para vivir (P08). Calcule: Brinde el estimador puntual de la media poblacional. Calcule el intervalo de confianza de la media poblacional. Calcule los intervalos de confianza de la media según si el individuo vive en el área urbana o rural (area2). En otras palabras, compare la media de la variable en esos dos grupos. Realice un gráfico de barras de error. Existe indicio de DIFERENCIA entre los dos grupos? Tienes 15 minutos! 5.6 Intervalo de una proporción 5.6.1 Definición En estadística, el intervalo de una proporción es un rango de valores posibles para la proporción de una característica en una población, que se estima a partir de una muestra aleatoria de la población. Al igual que con la media, el intervalo de una proporción se construye utilizando un nivel de confianza específico y se utiliza para determinar la precisión de la estimación de la proporción en la población. Por ejemplo, si se desea estimar la proporción de personas en una población que votará por un candidato específico, se puede seleccionar una muestra aleatoria de la población y estimar la proporción de personas que votarán por ese candidato en la muestra. A partir de esta estimación, se puede construir un intervalo de confianza que contendrá el valor real de la proporción en la población con un cierto nivel de confianza. El ancho del intervalo depende del tamaño de la muestra y del nivel de confianza especificado. A medida que el tamaño de la muestra aumenta, el intervalo se estrecha y se vuelve más preciso. Del mismo modo, a medida que se aumenta el nivel de confianza, el intervalo se amplía y se vuelve menos preciso. El intervalo de una proporción es una herramienta útil en la inferencia estadística, ya que permite a los investigadores cuantificar la incertidumbre en una estimación de la proporción y determinar si una diferencia entre dos proporciones es estadísticamente significativa. 5.6.2 Fórmula Recuerda que en este caso, al igual que en la media, todo gira en torno a los principios de la curva normal, el número de desviaciones estándar/errores estándar a la izquierda y a la derecha, el teorema central del límite y la ley de los grandes números. Si alguno de estos conceptos no están claros, te recomiendo regresar a la sesión 4 y repasarlos! Para calcular el intervalo de confianza de una proporción variamos un poco la fórmula que ya conocemos hasta ahora. Primero hay que tener en cuenta que cuando calculamos la proporción, nos estamos refiriendo específicamente a la proporción de UNA CATEGORÍA de una variable CATEGÓRICA. Hago el énfasis en ello porque siempre se genera la confusión de “a qué le estoy calculando la proporción”. Dicho de otra manera, nosotros debemos poner el ojo en una categoría de una variable nominal/ordinal al principio de este cálculo. \\[\\text{Intervalo de confianza para una proporción: } \\hat{p} \\pm z \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\] Donde: \\(\\hat{p}\\) = Proporción muestral de la categoría elegida z = Puntuación crítica dependiendo de nuestro nivel de confianza elegido \\(\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\) = Error estándar de una proporción 5.6.3 IC de proporción con la fórmula Primero ubiquemos una variable categórica. Utilicemos la p11.1: ¿Qué tan desigual es el acceso de los peruanos a la EDUCACIÓN? 1. Muy desigual 2. Poco desigual 3. Nada desigual #Configuramos nuestra variable como factor enades$p11.1&lt;-factor(enades$p11.1, # Nombre de la variable a convertir levels=1:3, # Definimos los niveles (esta variable sólo tenía 2 niveles) labels=c(&quot;Muy desigual&quot;, &quot;Poco desigual&quot;, &quot;Nada desigual&quot;)) #Colocamos sus etiquetas La muestra se divide entre estas tres opciones. Ahora elegimos UNA CATEGORÍA de estas tres a la que vamos a calcular la proporción. En este caso vamos a elegir la proporción de individuos que afirmó que el acceso a la educación en el Perú es “Muy desigual”. #Calculamos p enades |&gt; count(p11.1) |&gt; drop_na(p11.1) |&gt; mutate(p=n/sum(n)) ## # A tibble: 3 × 3 ## p11.1 n p ## &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Muy desigual 912 0.610 ## 2 Poco desigual 503 0.336 ## 3 Nada desigual 80 0.0535 Ahora sabemos que nuestro \\(\\hat{p}\\) = 0.59 p&lt;-0.61003344 El número total de casos es: n&lt;- 912+503+80 Ahora definimos la puntuación crítica. Cuánto era para 95% de confianza? z&lt;-1.96 Ahora el error estándar \\(\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\) error_estandar&lt;- sqrt((p*(1-p))/n) Nuestro límite inferior es la proporción muestral menos z*error estándar: limite_inferior&lt;- p-z*error_estandar limite_inferior ## [1] 0.585309 Y el límite superior es la proporción muestral más z*error estándar: limite_superior&lt;- p+z*error_estandar limite_superior ## [1] 0.6347579 Lo podemos colocar todo en un data frame resultados&lt;-data.frame(p, error_estandar, limite_inferior, limite_superior) resultados |&gt; kbl() |&gt; kable_styling() p error_estandar limite_inferior limite_superior 0.6100334 0.0126145 0.585309 0.6347579 5.6.4 IC de proporción con prop.test() Ahora bien, también podemos utilizar la función prop.test(): Recordemos: enades |&gt; count(p11.1) |&gt; drop_na(p11.1) |&gt; mutate(p=n/sum(n)) ## # A tibble: 3 × 3 ## p11.1 n p ## &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Muy desigual 912 0.610 ## 2 Poco desigual 503 0.336 ## 3 Nada desigual 80 0.0535 Colocamos la frecuencia de la categoría elegida y el tamaño total de la muestra. prop.test(912, 1495)$conf.int ## [1] 0.5847202 0.6347751 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 Por qué colocamos frecuencia? Porque así está configurada esta función. 5.6.5 IC de proporción según grupos Ahora comparemos la proporción elegida (aquellos que creen que el acceso de los peruanos a la EDUCACIÓN es MUY DESIGUAL) entre el sector rural y urbano (area2). enades$area2&lt;- factor(enades$area2, # Nombre de la variable a convertir levels=1:2, # Definimos los niveles (esta variable sólo tenía 2 niveles) labels=c(&quot;Urbano&quot;, &quot;Rural&quot;)) #Colocamos sus etiquetas Primero, nos tenemos que preguntar cuál es la frecuencia en cada grupo enades |&gt; group_by(area2) |&gt; drop_na(p11.1) |&gt; count(p11.1) |&gt; mutate(p=n/sum(n)) ## # A tibble: 6 × 4 ## # Groups: area2 [2] ## area2 p11.1 n p ## &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Urbano Muy desigual 769 0.618 ## 2 Urbano Poco desigual 409 0.329 ## 3 Urbano Nada desigual 67 0.0538 ## 4 Rural Muy desigual 143 0.572 ## 5 Rural Poco desigual 94 0.376 ## 6 Rural Nada desigual 13 0.052 Ahora calculamos la función teniendo en cuenta que: En el primer grupo hay 769 casos de éxito de un total de 1273. Lo ingresamos a la función: prop.test(x=c(769), n=c(769+409+67))$conf.int ## [1] 0.5899485 0.6446582 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 En el segundo grupo hay 143 casos de éxito de un total de 257. prop.test(x=c(143), n=c(143+94+13))$conf.int ## [1] 0.5080285 0.6337218 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 Lo podemos ordenar en un data.frame. resultados_prop&lt;- data.frame(Grupo =c(&quot;Urbano&quot;, &quot;Rural&quot;), P =c(0.61767068, 0.57200000 ), Lim_inf=c(0.5899485, 0.5080285), Lim_sup= c(0.6446582,0.6337218)) resultados_prop ## Grupo P Lim_inf Lim_sup ## 1 Urbano 0.6176707 0.5899485 0.6446582 ## 2 Rural 0.5720000 0.5080285 0.6337218 Lo visualizamos: resultados_prop |&gt; #Data ggplot()+ #Iniciamos el ggplot. A partir de ahora son +! ya no |&gt;! aes(y=p, x=Grupo)+ #Los grupos en el eje X y la media en el eje Y geom_errorbar(aes(ymin=Lim_inf, ymax=Lim_sup), width=0.2)+ #Graficamos la barra de error xlab(&quot;Procedencia&quot;) + #Etiqueta del eje X ylab(&quot;P la cobertura en educación es Muy Desigual&quot;) # Etiqueta del eje y Otra alternativa es pedirlos al mismo tiempo en la función prop.test(). En este caso lo que nos muestra, es el intervalo de la diferencia. prop.test(x=c(769, 143), n=c(1273, 257))$conf.int ## [1] -0.02108879 0.11641800 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 En este caso, se sigue la siguiente interpretación: Si el intervalo de confianza no contiene el valor cero, esto sugiere que las proporciones de los dos grupos son significativamente diferentes y que la hipótesis nula de que las proporciones son iguales debe ser rechazada. Por otro lado, si el intervalo de confianza contiene el valor cero, no podemos rechazar la hipótesis nula y no podemos concluir que las proporciones son significativamente diferentes. 5.7 Ejercicio 3 PREGUNTA Utilizando la variable “ideología2” (1: Izquierda, 2:Centro, 3:Derecha): Realice lo siguiente: Brinde el estimador puntual de la proporción de población de Izquierda en el Perú. Calcule el intervalo de confianza de la proporción poblacional de Izquierda en el Perú. Calcule por separado, utilizando prop.test(), la proporción de población de izquierda en el área urbano y rural (area2). Mediante la función prop.test(), compare los dos grupos y evalúe el intervalo de confianza de la diferencia en los p poblacionales. "],["prueba-de-hipótesis-t.test-y-prop.html", "Sesión 6 Prueba de hipótesis: t.test y prop.test 6.1 Prueba de hipótesis 6.2 Tipos error posibles 6.3 Tipos de prueba de hipótesis 6.4 Diferencia de medias (t.test) 6.5 Ejercicio 1 6.6 Recuerda!", " Sesión 6 Prueba de hipótesis: t.test y prop.test 6.1 Prueba de hipótesis Una prueba de hipótesis es un método para determinar si una afirmación sobre una población es verdadera o falsa, basándose en la información obtenida de una muestra aleatoria de la población. Este enfoque proporciona una forma sistemática y rigurosa para tomar decisiones informadas y hacer inferencias sobre la población en función de la evidencia empírica. Para aplicar una prueba debemos seguir pasos muy ordenados y entender qué estamos haciendo en cada uno de ellos. En términos referenciales, es como seguir un proceso de investigación policial! Vamos a utilizar esta analogía! 6.1.1 Paso 1: Establecer hipótesis En este punto somos como detectives (como Benoit Blanc en Knives Out) y estas son nuestras hipótesis de investigación. Si vamos a investigar un crimen partimos con la H0 que la persona investigada es inocente. Nuestra hipótesis alterna es que es culpable! Las hipótesis son afirmaciones o suposiciones acerca de una población o de un conjunto de datos que se pretende analizar. En el contexto de las pruebas de hipótesis, se suelen plantear dos hipótesis: la hipótesis nula (H0) y la hipótesis alternativa (H1). Hipótesis Descripción Hipótesis nula (H0) La hipótesis nula es una afirmación o suposición inicial que se establece para ser probada. En general, representa la idea de que no hay efecto, cambio o diferencia en el fenómeno o grupo(s) que se está estudiando. Es la hipótesis que se asume como verdadera y que se intenta refutar mediante la prueba de hipótesis. Hipótesis alternativa (H1) La hipótesis alternativa es lo que un investigador quiere demostrar. Representa la idea de que sí hay un efecto, cambio o diferencia en el fenómeno o grupo(s) que se está estudiando. Es la hipótesis que se acepta si los datos proporcionan suficiente evidencia para rechazar la hipótesis nula. Tener en cuenta que la forma cómo planteamos nuestras hipótesis va a repercutir en todo el flujograma. Normalmente vas a tener que recordar, para cada tipo de prueba que veamos en este curso, cuáles son las hipótesis nula y alterna. Es clave acordarte el orden 6.1.2 Paso 2: Verificar supuestos Antes de interrogar o investigar al sospechoso, el detective necesita asegurarse de que tiene todas las herramientas y condiciones adecuadas para hacerlo. Esto puede incluir asegurarse de que el interrogatorio se realice en un lugar adecuado o que se sigan ciertos protocolos. Entender previamente estas características nos permitirá investigar mejor! Es nuestra escena del crimen! Recuerdas que en clases anteriores habíamos hablado sobre los principios que fundamentan la inferencia estadística? Es decir, los principios de la curva normal, desviaciones estándar, errores estándar (en el caso de las distribuciones muestrales), etc…. eso también se aplica aquí! Partimos de la idea de que si se extraen muchas muestras repetidas (como en la clase anterior), los estadísticos muestrales se centrarán alrededor de un valor con una distribución aproximadamente normal. En este caso debemos corroborar ciertas características de la distribución de nuestra muestra. Algunas de estas: DISTRIBUCIÓN NORMAL: Que las variables provengan de una distribución gaussiana o normal. VARIANZAS IGUALES: Que las varianzas poblacionales sean iguales. Es decir, que la curva de distribución muestral en cada grupo analizado sea homogénea. Si son iguales, el camino de la investigación se dirigirá por un lado, si es diferente irá por otro. 6.1.3 Paso 3: Establecer nivel de significancia Cuando investigamos un crimen debemos cotejar el comportamiento del investigado frente a una actitud vista como normal o regular. El detective decide cuánta evidencia necesita antes de considerar al sospechoso como culpable. Por ejemplo, puede decidir que necesita al menos un 95% de certeza para considerar al sospechoso culpable. Como en el caso del intervalo de confianza, elegir el nivel de confianza con el que estamos trabajando es vital. Técnicamente, el nivel de significancia, denotado generalmente como α (alfa), es un valor umbral que se utiliza para determinar si un p-valor es lo suficientemente pequeño como para rechazar la hipótesis nula. Dicho en otras palabras, es el riesgo que estamos dispuestos a asumir de hacer una afirmación incorrecta basándonos en nuestra muestra. Por ejemplo, si se realiza una prueba de hipótesis (cualquier) con un nivel de significancia del 5% (0.05), esto significa que: Este número va a ser nuestra referencia. En este caso vamos a considerar una probabilidad máxima del 5% de que los resultados observados se deban al azar. Si el valor p obtenido en la prueba de hipótesis es menor que el nivel de significancia establecido, se rechaza la hipótesis inicial (nula) y se concluye que hay evidencia suficiente para elegir la hipótesis alternativa. Es importante destacar que el nivel de significancia elegido puede tener un impacto en la interpretación de los resultados y que, en última instancia, es el investigador quien debe decidir el nivel adecuado en función del contexto de la investigación y del grado de incertidumbre que esté dispuesto a asumir. 6.1.4 Paso 4: Aplicar test estadístico y obtener p-value Ahora debemos recopilar evidencia! El detective recopila y analiza las pruebas contra el sospechoso. El p-valor es similar a la fuerza de la evidencia contra el sospechoso. Una evidencia muy fuerte (p-valor bajo) sugiere que el sospechoso podría ser culpable. Test Estadístico: Es como una fórmula o herramienta matemática que usamos para comparar nuestros datos con lo que esperamos bajo la hipótesis nula. Nos da un número que nos indica cuánto difieren nuestros datos de esa expectativa. p-value: Una vez que tenemos el resultado del test, calculamos el p-value. Este valor nos dice qué tan probable es obtener un resultado como el que obtuvimos (o más extremo) si la hipótesis nula fuera cierta. Un p-value pequeño sugiere que nuestros datos son raros bajo la hipótesis nula. 6.1.5 Paso 5: Tomar una decisión Basándose en la evidencia recolectada, el detective decide si hay suficiente evidencia para considerar al sospechoso como culpable (rechazar la hipótesis nula) o si la evidencia no es suficiente (no rechazar la hipótesis nula). Tenemos los siguientes escenarios Resultado Decisión \\(p-value &lt;\\alpha\\) Rechazamos la hipótesis nula. \\(p-value &gt;=\\alpha\\) No rechazamos la hipótesis nula. Considerar lo siguiente: La convención tradicional es considerar un resultado como estadísticamente significativo si el p-valor es menor que 0.05 (es decir, p&lt;0.05). Es esencial recordar que el umbral de 0.05 es una convención y, dependiendo del contexto o la disciplina, se pueden usar otros valores de α. Cuando el p-valor es menor que 0.05 (o cualquier otro nivel de significancia que hayas establecido), es correcto decir que “rechazamos la hipótesis nula”. Sin embargo, es importante ser cauteloso con la terminología que usamos después de eso. No es correcto decir que “aceptamos la hipótesis alternativa”. La razón es que las pruebas de hipótesis no están diseñadas para probar directamente la hipótesis alternativa, sino para evaluar la evidencia contra la hipótesis nula. En su lugar, es más adecuado y preciso decir que “tenemos suficiente evidencia para respaldar la hipótesis alternativa”, que los datos “son consistentes con la hipótesis alternativa” o que encontramos pruebas “estadísticamente significativas”. 6.1.6 Paso 6: Interpretación El detective, después de tomar su decisión, reflexiona sobre el caso. Considera cómo encaja la evidencia en el panorama general, si hay otras personas involucradas o si hay otros factores que no se han considerado. Luego, comunica sus hallazgos y conclusiones a las partes interesadas. Independientemente de la decisión tomada en el paso anterior, es crucial interpretar los resultados en el contexto del estudio o experimento. Esto puede incluir discutir la magnitud del efecto, la relevancia práctica, las limitaciones y las posibles implicaciones. Escenario 1: p-valor &lt; α Luego de realizar la [nombre de la prueba de hipótesis], dado que se obtuvo un p-valor de [valor específico del p-valor, por ejemplo, 0.03], que es menor que nuestro nivel de significancia establecido de [valor específico de α, por ejemplo, 0.05], hay evidencia suficiente para rechazar la hipótesis nula. Por lo tanto, concluimos que [interpretación específica del contexto, por ejemplo, ‘las medias del ingreso es diferente entre hombres y mujeres’]. Escenario 2: p-valor &gt;= α Luego de realizar la [nombre de la prueba de hipótesis], dado que se obtuvo un p-valor de [valor específico del p-valor, por ejemplo, 0.03], que es mayor que nuestro nivel de significancia establecido de [valor específico de α, por ejemplo, 0.05], no encontramos evidencia suficiente para rechazar la hipótesis nula. Esto sugiere que, basándonos en los datos actuales, no podemos afirmar que [interpretación específica del contexto, por ejemplo, ‘las medias del ingreso es diferente entre hombres y mujeres’]. 6.2 Tipos error posibles ¿En el marco de una investigación cuáles son los errores que puede cometer el investigador? En estadística inferencial, siempre hay un grado de incertidumbre al hacer inferencias sobre una población basándonos en una muestra. Los errores de Tipo I y Tipo II representan los dos tipos principales de errores incorrectos que podemos cometer. Al tener claros estos errores, podemos definir y controlar los riesgos asociados con nuestras decisiones. Error tipo I: Se comete un error Tipo I cuando rechazamos la hipótesis nula cuando, en realidad, es verdadera. En otras palabras, determinamos que hay un efecto (o diferencia) cuando en realidad no lo hay. EJ: El detective concluye que el sospechoso es culpable basándose en las evidencias que tiene. Sin embargo, en la realidad, el sospechoso es inocente. En este caso, el detective ha cometido un error Tipo I, ya que ha declarado culpable a una persona inocente. Error tipo II: Se comete un error Tipo II cuando no rechazamos la hipótesis nula cuando, en realidad, es falsa. Esto significa que no detectamos un efecto (o diferencia) cuando en realidad sí existe. EJ: El detective decide que no hay suficientes pruebas para declarar al sospechoso como culpable y lo deja en libertad. En la realidad, el sospechoso sí era el culpable del crimen. En este escenario, el detective ha cometido un error Tipo II, ya que ha declarado inocente a una persona que en realidad era culpable. Ambos tipos de errores son inevitables en estadística y en la toma de decisiones basada en evidencia, como en la investigación criminal. Por eso es esencial ser consciente de ellos, entender sus consecuencias y tratar de minimizarlos tanto como sea posible en función del contexto y las prioridades. 6.3 Tipos de prueba de hipótesis Ahora bien, existen múltiples pruebas de hipótesis dependiendo de: Características de la data: Con fines de este curso, vamos a abordar un conjunto de pruebas de hipótesis que están construidas para tratar con datos que siguen una distribución normal. Este tipo de pruebas de hipótesis se le conoce como métodos paramétricos. En otras palabras, vamos a asumir que las variables que estamos eligiendo provienen de una distribución normal. Objetivo del investigador: Una prueba de hipótesis nos puede servir para evaluar muchas afirmaciones sobre la población. En este curso vamos a abordar algunas de las preguntas de investigación más conocidas: La media de esta variable numérica es distinta en dos grupos a nivel de la población? La media de esta variable numérica es distinta en tres a más grupos a nivel de la población? Dos variables categóricas están asociadas en la población? Dos variables numéricas están asociadas en la población? 6.4 Diferencia de medias (t.test) La prueba T para comparar una media en dos grupos es una técnica estadística que se utiliza para determinar si la diferencia entre las medias de dos grupos es estadísticamente significativa o simplemente el resultado del azar. La prueba T se basa en la distribución T de Student, que es una distribución de probabilidad que se utiliza cuando el tamaño de la muestra es pequeño o la varianza poblacional es desconocida. Será bastante común que en la descripción de una prueba de hipótesis se haga referencia a una distribución teórica que ayudará a establecer las probabilidades. Aquí está el core estadístico que sustenta la inferencia! 6.4.1 Pregunta de investigación Para iniciar, debemos tener claro nuestra pregunta que deseamos responder. ¿El monto mínimo promedio necesario para que un hogar pueda subsistir (p08) será diferente entre el área urbana y rural (area2) a nivel poblacional? 6.4.2 Paso 0: Análisis exploratorio de datos (EDA) No está en el flujograma, pero siempre debes seguir algunos pasos previos. Desde lo más general a lo más específico, nosotros debemos: Abrir la base de datos. Vamos a seguir usando ENADES. Puedes ver el cuestionario aqui: library(pacman) p_load(haven, tidyverse, lsr, kableExtra) enades&lt;-read_spss(&quot;data/ENADES_2022.sav&quot;) CONFIGURACIÓN ADECUADA DE LAS VARIABLES A UTILIZAR En este caso deseo comparar la variable monto mínimo mensual que requiere su hogar para vivir (p08)… enades$p08&lt;-as.numeric(enades$p08) str(enades$p08) ## num [1:1530] 20000 16000 15000 15000 10000 10000 10000 10000 10000 10000 ... …En los grupos establecidos por la variable ámbito (urbano/rural) enades$area2&lt;-factor(enades$area2, # Nombre de la variable a convertir levels=1:2, # Definimos los niveles (esta variable sólo tenía 2 niveles) labels=c(&quot;Urbano&quot;, &quot;Rural&quot;)) #Colocamos sus etiquetas str(enades$area2) ## Factor w/ 2 levels &quot;Urbano&quot;,&quot;Rural&quot;: 1 1 1 1 1 1 1 1 1 1 ... EXPLORACIÓN DE LOS ESTADÍSTICOS MUESTRALES Si bien nos interesa calcular la media poblacional, primero tenemos que tener en cuenta cuál es la media en nuestra muestra. Ahora hacemos un primer sondeo de cuál es la media muestral… enades |&gt; summarise(mean(p08, na.rm=T)) ## # A tibble: 1 × 1 ## `mean(p08, na.rm = T)` ## &lt;dbl&gt; ## 1 2334. …y cuál es la media muestral en cada uno de los grupos seleccionados que deseamos comparar. enades |&gt; group_by(area2) |&gt; summarise(mean(p08, na.rm=T)) ## # A tibble: 2 × 2 ## area2 `mean(p08, na.rm = T)` ## &lt;fct&gt; &lt;dbl&gt; ## 1 Urbano 2490. ## 2 Rural 1497. Esto nos ayuda a corroborar que tenemos toda la información necesitaria lista para llevar a cabo una prueba de hipótesis. 6.4.3 Paso 1: Establecer hipótesis Debemos plantear las hipótesis nula y alternativa. Recuerda que cada prueba tiene su hipótesis nula, por lo que hay que memorizar algunas de estas. En el caso de la Prueba T, las hipótesis son las siguientes: Hipótesis Descripción Notación Hipótesis nula Las medias poblacionales son iguales \\(H_0: \\mu_1 = \\mu_2\\) Hipótesis alterna Las medias poblacionales son diferentes $H_1: _1 _2 $ Estas son las hipótesis que vamos a validar con nuestra prueba. 6.4.4 Paso 2: Verificar supuestos INDEPENDENCIA Las muestras deben ser independientes. El muestreo debe ser aleatorio. Vamos a asumir ello porque normalmente no tenemos control sobre el proceso de muestreo. DISTRITUCIÓN NORMAL Para los fines de este curso, asumimos que la variable numérica proviene de una distribución normal en la población. HOMOGENEIDAD DE VARIANZAS Identificamos si las varianzas son iguales en los dos grupos analizados. En el caso de que sean diferentes, vamos a necesitar hacer un **ajuste* a la fórmular de cálculo. Veamos antes una visualización de los datos a través de un boxplot: enades |&gt; ggplot() + aes(x = p08, fill = area2) + geom_boxplot() + scale_fill_manual(values = c(&quot;#00BFC4&quot;, &quot;#F8766D&quot;)) + labs(title = &quot;Distribución de variable p08 por grupo&quot;, x = &quot;Variable&quot;, y = &quot;Densidad&quot;) + coord_flip() ## Warning: Removed 127 rows containing non-finite values ## (`stat_boxplot()`). Esto lo corroboramos con el gráfico de cajas. El 50% superior en el caso urbano tiene un rango mucho mayor. Asimismo, podemos ver algunos valores extremos que se alejan a valores muy altos, en el caso del sector Urbano. Para fines de este ejercicio, vamos a considerar que las varianzas son diferentes en ambos grupos analizados. (después vamos a requerir hacer una prueba para hacer esta afirmación!) 6.4.5 Paso 3: Establecer nivel de significancia Estamos trabajando a un 95% de confianza, por lo que nuestro nivel de significancia será 0.05. \\[\\alpha = 0.05\\] 6.4.6 Paso 4: Calcular estadístico de prueba y p-valor Ahora utilizemos la función t.test() para realizar el cálculo del Estadístico T y el cálculo del p-valor. t.test(p08 ~ area2, #Colocamos la variable numérica y la variable grupo. Ese símbolo ~ (en Windows) es ALT + 126 alternative = &quot;two.sided&quot;, # Siempre que comparemos un estadístico en dos grupos usaremos &quot;two.sided&quot;. data = enades, # Precisamos la data var.equal=F) # Precisamos si las varianzas son iguales. En este caso colocamos F, porque identificamos diferencia ## ## Welch Two Sample t-test ## ## data: p08 by area2 ## t = 10.992, df = 466.14, p-value &lt; 2.2e-16 ## alternative hypothesis: true difference in means between group Urbano and group Rural is not equal to 0 ## 95 percent confidence interval: ## 815.0508 1169.9052 ## sample estimates: ## mean in group Urbano mean in group Rural ## 2489.569 1497.091 El estadístico de prueba en este caso es el Estadítico T, el cual es 10.992. Ahora bien, lo que hace la prueba es comparar este valor observable del Estadístico T con un valor teórico, de acuerdo a la distribución T. Dicha comparación lo que arroja es una probabilidad de obtener ese valor observado, en caso la hipótesis nula (medias iguales) es verdadera En este caso, nuestro p-value es p-value &lt; 2.2e-16. El cual es un número muy pequeño. RECUERDA: El número 2.2e-16 es una forma abreviada de escribir un número muy pequeño en notación científica. En este caso, equivale a 0.00000000000000022 o 2.2 multiplicado por 10 elevado a la potencia -16. Es común utilizar esta notación en estadística y otras áreas de la ciencia para representar números muy grandes o muy pequeños de manera más concisa. 6.4.7 Paso 5: Tomar una decisión Tenemos los siguientes escenarios Resultado Decisión \\(p-value &lt;\\alpha\\) Rechazamos la hipótesis nula. \\(p-value &gt;=\\alpha\\) No rechazamos la hipótesis nula. En nuestro caso nuestro habíamos escogido un \\(\\alpha = 0.05\\) por lo que al obtener un p-valor de 2.2e-16 (0.00000000000000022) rechazamos la hipótesis nula de que nuestras medias poblacionales son iguales. En otras palabras, un p-valor de 0.00000000000000022 significa que hay una probabilidad muy baja de obtener los resultados observados en la muestra si la verdadera diferencia entre las medias poblacionales es cero (hipótesis nula). Es decir, si la hipótesis nula fuera verdadera y no hay diferencia real entre las medias poblacionales, la probabilidad de observar una diferencia tan grande o mayor entre las medias muestrales es muy baja, de solo 0.000002. 6.4.8 Paso 6: Interpretación Ahora bien, al finalizar este proceso debemos interpretar nuestros resultados. En este punto tienes que recordar que estamos trabajando con probabilidades, no existen certezas absolutas, por lo tanto, nuestra interpretación final debe considerar ello. Deberíamos concluir: Luego de realizar una prueba T, a un 95% de confianza, obtuvimos un p-valor de 2.2e-16, por lo que rechazamos la hipótesis nula de que el monto mínimo mensual que requiere su hogar para vivir es igual en el área urbana y en el área rural. Por ello, concluimos que existen diferencias estadísticamente significativas en ambos grupos poblacionales. Luego de realizar la Prueba T para diferencia de medias, dado que se obtuvo un p-valor de 2.2e-16, que es menor que nuestro nivel de significancia establecido de 0.05], hay evidencia suficiente para rechazar la hipótesis nula. Por lo tanto, concluimos que existe diferencia estadísticamente significativas en el monto mínimo promedio necesario para que un hogar pueda subsistir entre el área urbana y rural. 6.5 Ejercicio 1 Considera la variable p19 (ideología). Deseamos saber si existe diferencia en el promedio de esta variable en el sector rural y urbano. Realice una comparación de medias en ambos grupos utilizando la prueba de hipótesis más pertinente. Muestre sus resultados e interprete. 6.6 Recuerda! Prueba de hipótesis para igualdad de varianzas Como te sugerí líneas arriba, siempre es bueno realizar una exploración visual con un boxplot para encontrar indicios sobre la existencia de homogeneidad de varianzas en dos o más grupos. Sin perjuicio de ello, para poder verificar este supuesto de homogenedidad de varianzas de forma más rigurosa podemos aplicar una Prueba de Levene de Homogeneidad de Varianzas. library(DescTools) LeveneTest(enades$p08, enades$area2) ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 1 14.258 0.0001661 *** ## 1401 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Recordamos nuestras hipótesis a validar: Hipótesis Descripción Notación Hipótesis nula Las varianzas poblacionales son homogéneas \\(H_0: v_1 = v_2\\) Hipótesis alterna Las varianzas poblacionales son diferentes $H_1: v_1 v_2 $ Luego de realizar una prueba de Levene, a un 95% de confianza, obtuvimos un p-valor de 0.0001660599, por lo que rechazamos la hipótesis nula de que la varianza del monto mínimo mensual que requiere su hogar para vivir es igual/homogénea en el área urbana y en el área rural. Por ello, concluimos que existen diferencias estadísticamente significativas en las varianzas de ambos grupos poblacionales. Valores faltantes en las encuestas En las encuestas, los valores perdidos son aquellos que faltan en las respuestas proporcionadas por los encuestados. Esto puede suceder porque el encuestado decidió no responder a la pregunta, porque no entendió la pregunta o porque la pregunta simplemente no se aplicaba a él o ella. Para manejar los valores perdidos, a menudo se utiliza la técnica de imputación, que implica reemplazar los valores faltantes por algún valor estimado. En algunos casos, se puede asignar un valor específico, como 99 o 999, para indicar que el encuestado no sabe o no responde a la pregunta. Este enfoque se utiliza comúnmente en encuestas de opinión pública y otras encuestas que involucran preguntas sensibles. Sin embargo, es importante tener en cuenta que asignar un valor específico a los valores perdidos puede afectar los resultados de la encuesta y la validez de los análisis estadísticos posteriores. Por lo tanto, es importante evaluar cuidadosamente las estrategias de manejo de valores perdidos y elegir la opción más adecuada para el conjunto de datos y el análisis específicos. "],["anova-comparación-en-más-de-dos-muestras.html", "Sesión 7 ANOVA: Comparación en más de dos muestras 7.1 Recordemos 7.2 ANOVA de un factor 7.3 Identificar el/los grupos diferentes 7.4 Ejercicio 1 7.5 Ejercicio 2", " Sesión 7 ANOVA: Comparación en más de dos muestras 7.1 Recordemos 7.1.1 Flujograma Anteriormente habíamos establecido algunos pasos básicos para entender el proceso de utilización de una prueba de hipótesis. 7.1.2 Qué sigue? 7.2 ANOVA de un factor El análisis de varianza (ANOVA) de un factor en R es una técnica estadística utilizada para comparar la media de una variable numérica entre más de dos grupos. Se realiza un ANOVA de un factor cuando se tiene un solo factor categórico (con tres o más niveles) que se utiliza para agrupar los datos, y se quiere determinar si existe una diferencia estadísticamente significativa entre las medias de los grupos. El ANOVA es una herramienta útil para analizar datos experimentales en los que se desea comparar las medias de más de dos grupos. En lugar de realizar múltiples pruebas t de dos muestras, el ANOVA nos permite realizar una sola prueba para determinar si hay una diferencia significativa entre los grupos. Los pasos para aplicación del ANOVA son los mismos que los seguidos para el T de Student, visto la clase anterior. 7.2.1 Pregunta de investigación 7.2.2 Paso 0: Análisis exploratorio de datos (EDA) ABRIR LA DATA library(pacman) p_load(haven, tidyverse, lsr, kableExtra) enades&lt;-read_spss(&quot;https://github.com/ChristianChiroqueR/banco_de_datos/raw/main/ENADES_2022.sav&quot;) CONFIGURACIÓN ADECUADA DE LAS VARIABLES A UTILIZAR 7.2.2.1 Nuestra numérica: Índice aditivo En este caso deseamos realizar un índice aditivo de Percepción sobre la desigualdad en el acceso a servicios públicos. Para ello, vamos a utilizar estas cuatro variables: Volvemos a recodificar enades&lt;-enades |&gt; mutate(p11.1n=case_when(p11.1==1~ 3, p11.1==2~2, p11.1==3~1, TRUE~NA_real_), p11.2n=case_when(p11.2==1~ 3, p11.2==2~2, p11.2==3~1, TRUE~NA_real_), p11.3n=case_when(p11.3==1~ 3, p11.3==2~2, p11.3==3~1, TRUE~NA_real_), p11.4n=case_when(p11.4==1~ 3, p11.4==2~2, p11.4==3~1, TRUE~NA_real_)) Ahora sí podremos realizar el índice aditivo. enades&lt;-enades |&gt; mutate(indice_aditivo=p11.1n+p11.2n+p11.3n+p11.4n) enades |&gt; count(indice_aditivo) ## # A tibble: 10 × 2 ## indice_aditivo n ## &lt;dbl&gt; &lt;int&gt; ## 1 4 5 ## 2 5 3 ## 3 6 15 ## 4 7 35 ## 5 8 82 ## 6 9 145 ## 7 10 274 ## 8 11 337 ## 9 12 550 ## 10 NA 84 library(scales) enades$indice_aditivo&lt;-rescale(enades$indice_aditivo, to=c(0,10)) #Aquí mencionas que quieresque la nueva escala sea de 0 al 10. 7.2.2.2 Nuestros grupos enades$ambito&lt;-factor(enades$ambito, # Nombre de la variable a convertir levels=1:3, # Definimos los niveles (esta variable sólo tenía 2 niveles) labels=c(&quot;Lima Metropolitana&quot;, &quot;Perú urbano&quot;, &quot;Perú rural&quot;)) #Colocamos sus etiquetas table(enades$ambito) ## ## Lima Metropolitana Perú urbano Perú rural ## 536 737 257 EXPLORACIÓN DE DATOS MUESTRALES enades |&gt; group_by(ambito) |&gt; summarise(Media=mean(indice_aditivo, na.rm = T)) ## # A tibble: 3 × 2 ## ambito Media ## &lt;fct&gt; &lt;dbl&gt; ## 1 Lima Metropolitana 8.48 ## 2 Perú urbano 8.17 ## 3 Perú rural 8.25 7.2.3 Paso 1: Establecer hipótesis Debemos plantear las hipótesis nula y alternativa. Recuerda que cada prueba tiene su hipótesis nula, por lo que hay que memorizar algunas de estas. En el caso de la Prueba T, las hipótesis son las siguientes: Hipótesis Descripción Hipótesis nula Las medias poblacionales en todos los grupos son iguales Hipótesis alterna Al menos una de las medias de las grupos es diferente de las demás. Estas son las hipótesis que vamos a validar con nuestra prueba. 7.2.4 Paso 2: Verificar supuestos INDEPENDENCIA Las muestras deben ser independientes. El muestreo debe ser aleatorio. Vamos a asumir ello porque normalmente no tenemos control sobre el proceso de muestreo. DISTRITUCIÓN NORMAL Para los fines de este curso, asumimos que la variable numérica proviene de una distribución normal en la población. HOMOGENEIDAD DE VARIANZAS Para los fines de este curso, asumimos que la variable numérica posee homogeneidad de varianzas en cada grupo analizado. 7.2.5 Paso 3: Establecer nivel de significancia Estamos trabajando a un 95% de confianza, por lo que nuestro nivel de significancia será 0.05. \\[\\alpha = 0.05\\] 7.2.6 Paso 4: Calcular estadístico de prueba y p-valor Para calcular el ANOVA de un factor utilizamos la función aov(): anova1 = aov(enades$indice_aditivo~enades$ambito) summary(anova1) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## enades$ambito 2 30 15.123 4.34 0.0132 * ## Residuals 1443 5028 3.484 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## 84 observations deleted due to missingness En este caso, al igual que con las otras pruebas de hipótesis, se calcula un estadístico y se compara con una distribución teórica. 7.2.7 Paso 5: Tomar una decisión Tenemos los siguientes escenarios Resultado Decisión \\(p-value &lt;\\alpha\\) Rechazamos la hipótesis nula. \\(p-value &gt;=\\alpha\\) No rechazamos la hipótesis nula. Habíamos escogido un \\(\\alpha = 0.05\\) por lo que al obtener un p-valor de 0.0132 rechazamos la hipótesis nula de que nuestras medias poblacionales son iguales en todos los grupos. En otras palabras, un p-valor de 0.0132 significa que hay una probabilidad muy baja de obtener los resultados observados en la muestra si la verdadera diferencia entre las medias poblacionales entre grupos es cero (hipótesis nula). Esta probabilidad se encuentra por debajo de nuestro último nivel de rareza que estamos dispuestos a aceptar (0.05) por lo que rechazamos la H0. 7.2.8 Paso 6: Interpretación Ahora bien, al finalizar este proceso debemos interpretar nuestros resultados: Luego de realizar una prueba ANOVA, a un 95% de confianza, obtuvimos un p-valor de 0.0132, por lo que rechazamos la hipótesis nula de que la media del Índice de percepción de Desigualdad es igual en todos los ámbitos analizados (Lima Metropolitana, Perú urbano, Perú rural). Por ello, concluimos que existen diferencias estadísticamente significativas en alguno de los grupos poblacionales indicados. 7.3 Identificar el/los grupos diferentes 7.3.1 Pruebas post hoc: Test de Tukey Las pruebas de comparaciones múltiples son pruebas estadísticas que se utilizan para comparar múltiples grupos y determinar si hay diferencias significativas entre las medias de los grupos. En lugar de realizar varias pruebas t o ANOVA independientes para comparar cada par de grupos, las pruebas de comparaciones múltiples realizan todas las comparaciones de manera simultánea. La prueba Tukey, también conocida como prueba de rango múltiple de Tukey, es una prueba de comparaciones múltiples que se utiliza para determinar cuáles de los pares de grupos tienen medias significativamente diferentes. Esta prueba se basa en el rango de las medias de los grupos y en la estimación del error estándar de la media. La prueba de Tukey compara la diferencia entre las medias de cada par de grupos con una cantidad crítica que se basa en la variabilidad de los datos. Si la diferencia entre las medias de dos grupos es mayor que esta cantidad crítica, se considera que las medias son significativamente diferentes. Una vez que hemos creado nuestro objeto ANOVA (en nuestro caso llamado anova1), podemos solicitar la prueba Tukey sobre dicho objeto. comparacion = TukeyHSD(anova1) comparacion ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = enades$indice_aditivo ~ enades$ambito) ## ## $`enades$ambito` ## diff lwr upr ## Perú urbano-Lima Metropolitana -0.31593910 -0.5702069 -0.06167134 ## Perú rural-Lima Metropolitana -0.23833440 -0.5838902 0.10722141 ## Perú rural-Perú urbano 0.07760471 -0.2538591 0.40906848 ## p adj ## Perú urbano-Lima Metropolitana 0.0100916 ## Perú rural-Lima Metropolitana 0.2382426 ## Perú rural-Perú urbano 0.8468574 Para leer este resultado debemos preguntarnos dos cosas: ¿En qué parejas existe una diferencia significativa? Vemos el p-value. Estas se deben leer como Pruebas T calculada para cada pareja de grupos. ¿Cuáles eran las hipótesis que testeamos? Corrobora el resultado viendo el intervalo de la diferencia. Si el 0 está incluido en este intervalo, entonces dicha diferencia puede ser 0. Siempre hay una correspondencia: si el p valor no es significativo, el intervalo de la diferencia incluye al 0. 7.3.2 Visualización Exploramos el objeto que creamos arriba. diferencias_parejas = as.data.frame(comparacion[1]) diferencias_parejas ## enades.ambito.diff enades.ambito.lwr ## Perú urbano-Lima Metropolitana -0.31593910 -0.5702069 ## Perú rural-Lima Metropolitana -0.23833440 -0.5838902 ## Perú rural-Perú urbano 0.07760471 -0.2538591 ## enades.ambito.upr enades.ambito.p.adj ## Perú urbano-Lima Metropolitana -0.06167134 0.01009162 ## Perú rural-Lima Metropolitana 0.10722141 0.23824258 ## Perú rural-Perú urbano 0.40906848 0.84685736 Hemos generado un dataframe con los valores de las diferencias estimadas en cada pareja y los límites inferiores y superiores de cada diferencia estimada. Ahora creamos una columna adicional en dicho data frame que tenga el detalle de la pareja. diferencias_parejas$parejas = rownames(diferencias_parejas) Ahora solicitamos un gráfico de barras de error utilizando la librería ggplot2. diferencias_parejas |&gt; ggplot()+ aes(x=parejas, y=enades.ambito.diff)+ geom_errorbar(aes(ymin=enades.ambito.lwr, ymax=enades.ambito.upr), width=0.2)+ geom_text(aes(label=paste(round(enades.ambito.diff, 1))), vjust=-1, size=3)+ xlab(&quot;Comparaciones&quot;) + ylab(&quot;Diferencia encontrada&quot;)+ ylim(-1, 1) + coord_flip() + geom_hline(yintercept = 0, color = &quot;red&quot;, linetype=&quot;dotted&quot;) + theme_classic() Con este gráfico debemos corroborar los resultados que arroja la prueba de comparaciones múltiples de Tukey. 7.4 Ejercicio 1 Deseamos responder a la pregunta: ¿Existe una diferencia en el apoyo a un modelo intervencionista del Estado según la postura ideológica? Realice la prueba de hipótesis más pertinente. Muestre sus resultados e interprete. Considera las siguientes variables: ABROS4: En una escala de 1 a 10, ¿qué tan de acuerdo o en desacuerdo se encuentra con las siguientes afirmaciones respecto al Perú? - El Estado peruano debe implementar políticas firmes para reducir la desigualdad de ingresos entre ricos y pobres. ideologia2: Variable que distingue si la persona se identifica con una postura de izquierda, centro o derecha. 7.5 Ejercicio 2 Se cuenta con la hipótesis que el promedio de monto mínimo mensual que se requiere para vivir, en promedio, es menor si la persona tiene una ideología de izquierda y mayor si tiene una ideología de derecha. Realice la prueba de hipótesis más pertinente. Muestre sus resultados e interprete. Considera las siguientes variables: P08: Monto mínimo mensual que requiere su hogar para vivir. ideologia2: Las categorías de esta variable son 1:Izquierda, 2:Centro y 3:Derecha. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
